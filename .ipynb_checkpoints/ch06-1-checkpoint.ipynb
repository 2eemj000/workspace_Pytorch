{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57e3d2a-8189-4639-8f08-9bb89f893527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9630a70-1f52-4f40-97d6-d86c9ae028d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(1,16,5, padding=\"same\")\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "        self.cnn2 = nn.Conv2d(16,32,5, padding=\"same\")\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "        self.output = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74602883-11d7-498e-b37b-96f9d7bd208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_directory = r\"./gilbut_example/chap06/data/dogs-vs-cats/Cat/\"\n",
    "# dog_directory = r\"./gilbut_example/chap06/data/dogs-vs-cats/Dog/\"\n",
    "\n",
    "# cat_images_filepaths = sorted([os.path.join(cat_directory, f) for f in\n",
    "#                               os.listdir(cat_directory)])\n",
    "# dog_images_filepaths = sorted([os.path.join(dog_directory, f) for f in\n",
    "#                               os.listdir(dog_directory)])\n",
    "\n",
    "# images_filepaths = [*cat_images_filepaths, *dog_images_filepaths]\n",
    "\n",
    "# correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]\n",
    "\n",
    "# random.seed(42)\n",
    "# random.shuffle(correct_images_filepaths)\n",
    "# train_images_filepaths = correct_images_filepath[:400]\n",
    "# val_images_filepaths = correct_images_filepath[400:-10]\n",
    "# test_images_filepaths = correct_images_filepath[-10:]\n",
    "# print(len(train_images_filepaths), len(val_images_filepaths), len(test_images_filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c1bdf5-ef85-477a-80b7-aa35cfe84dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1568, out_features=512, bias=True)\n",
       "  (relu5): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (output): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "280ecb34-8242-4502-958c-3079ca0a395c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = torch.rand(64,1,28,28)\n",
    "model(images).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
