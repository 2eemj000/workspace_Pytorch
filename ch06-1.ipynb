{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57e3d2a-8189-4639-8f08-9bb89f893527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9630a70-1f52-4f40-97d6-d86c9ae028d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "  # 생성자\n",
    "  def __init__(self):\n",
    "    super(LeNet5,self).__init__()\n",
    "    self.features = nn.Sequential(nn.Conv2d(1,6,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2),\n",
    "                                  nn.Conv2d(6,16,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2),\n",
    "                                  nn.Conv2d(16,126,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2))\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(nn.Linear(126*3*3, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(64, 10), # 10: 분류하고자 하는 가지수 \n",
    "                                    nn.Softmax(dim=1))\n",
    "  def forward(self,x):\n",
    "      x = self.features(x)\n",
    "      x = self.flatten(x)\n",
    "      x = self.classifier(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74602883-11d7-498e-b37b-96f9d7bd208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c1bdf5-ef85-477a-80b7-aa35cfe84dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.rand(64, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280ecb34-8242-4502-958c-3079ca0a395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "dataset = datasets.MNIST(\"data\", download=True, transform=torchvision.transforms.ToTensor()) # \"data\" : 폴더명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6391b8d-129e-4f79-ab6d-a315e5f6e297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([60000, 28, 28]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.data), dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2045aa-99e4-41a9-bbe8-bbb587df0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "265ec9a9-0a8b-4dbc-a106-0d4b74e92ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a130d7b-0133-49ea-be10-bc45d5ae8d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in data_loader:\n",
    "  print(X_train.shape, y_label.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "593fe32d-9093-4c70-82e4-ad96c6b45efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b471bc46-741b-4435-a4ce-4df2b8e4398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57ebca6a-4320-443a-a07b-20c0a682ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for _ in range(epochs):\n",
    "  for X_train, y_label in data_loader:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db348bc1-8850-494e-9603-f176e517595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision.transforms.v2 as v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a99f40cc-7b2e-4468-a629-4503802b1f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST('data', download=True, transform=v2.ToTensor())\n",
    "dataset = FashionMNIST('data', download=True, transform=v2.ToTensor())\n",
    "dataset = CIFAR10('data', download=True, transform=v2.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edb928e7-ef07-4572-a822-5ea2ea1931c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb3beda-bbc9-4e97-8a5c-53421ba17b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader # 데이터를 쪼개서 넣도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaf0fa0e-bd2b-4a37-8df5-e5c3c7ac3245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1f66596adb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader(dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc8ab321-11be-4f9d-aba6-f71dabc1b0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "781.25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7eab644-89cc-4b86-8db9-47bb141c2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "  # 생성자\n",
    "  def __init__(self):\n",
    "    super(LeNet5,self).__init__()\n",
    "    self.features = nn.Sequential(nn.Conv2d(1,6,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2),\n",
    "                                  nn.Conv2d(6,16,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2),\n",
    "                                  nn.Conv2d(16,126,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2))\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(nn.Linear(126*3*3, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(64, 10), # 10: 분류하고자 하는 가지수 \n",
    "                                    nn.Softmax(dim=1))\n",
    "  def forward(self,x):\n",
    "      x = self.features(x)\n",
    "      print(x.shape)\n",
    "      x = self.flatten(x)\n",
    "      x = self.classifier(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09debedc-46b7-42b9-901d-7e5ddae2f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ec5cd0d-a834-4437-884e-588c7edc7562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in data_loader:\n",
    "    print(X_train)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fceede6-daff-4b25-925c-3c1d841f2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf0af628-268d-406d-825a-53d9e137b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd4cd6a-8e1b-4149-9aab-e3c561b6e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 126, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in data_loader:\n",
    "    optimizer.zero_grad() # 새로운 배치에 대한 기울기 계산 전에 이전값 초기화\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_label) # 예측값과 실제 레이블을 비교하여 손실을 계산\n",
    "    loss.backward() # 미분\n",
    "    optimizer.step() # 모델의 매개변수를 업데이트\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "020203f5-d13d-4de8-8960-337bfd4779a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('data', download=True, transform=v2.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d662d872-cc09-4399-935b-5aee50c912a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9bd44d0-277e-4f62-9004-b477cd6d9466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92135282-e159-4710-8b8d-cade9d69f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset():\n",
    "    def __init__(self):\n",
    "        self.data = list(range(100,200))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.rand(1,28,28),3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25c5566a-0285-498f-86dc-5cb2d0d24fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[1.4803e-02, 9.8698e-01, 2.3342e-01, 6.8072e-01, 2.0663e-01,\n",
       "            7.8339e-02, 7.5980e-01, 4.2388e-01, 5.6497e-01, 2.9908e-01,\n",
       "            7.1244e-01, 2.7954e-01, 1.0783e-01, 9.5204e-01, 6.4385e-01,\n",
       "            4.0082e-01, 8.2445e-01, 9.1371e-01, 8.6734e-01, 8.9162e-01,\n",
       "            9.0945e-01, 2.6737e-01, 3.6803e-01, 2.2952e-01, 6.3507e-01,\n",
       "            8.4534e-01, 6.4928e-01, 9.2117e-01],\n",
       "           [8.6865e-01, 4.5240e-01, 7.6792e-01, 5.1216e-01, 3.2371e-01,\n",
       "            6.5569e-01, 9.2699e-01, 6.8661e-02, 9.3128e-01, 4.0174e-01,\n",
       "            4.6663e-01, 7.9483e-01, 1.0402e-01, 4.2532e-01, 4.2811e-01,\n",
       "            4.9510e-01, 7.0137e-01, 2.2375e-01, 3.9242e-01, 3.5065e-01,\n",
       "            5.6711e-01, 8.8979e-01, 7.8003e-01, 9.1503e-01, 4.1891e-01,\n",
       "            8.1611e-01, 4.2612e-01, 1.7225e-02],\n",
       "           [3.0847e-01, 1.5001e-02, 4.0598e-01, 7.7372e-02, 2.0671e-01,\n",
       "            4.1785e-01, 5.9834e-01, 9.2348e-01, 7.1184e-01, 1.6174e-01,\n",
       "            7.5370e-01, 7.9886e-01, 6.3195e-01, 5.7073e-01, 7.3041e-01,\n",
       "            6.6358e-01, 6.0798e-01, 9.9921e-01, 7.5733e-01, 3.5628e-01,\n",
       "            2.8132e-01, 1.8683e-01, 7.0613e-01, 2.0917e-01, 2.8381e-01,\n",
       "            4.9315e-01, 8.7253e-01, 8.3030e-01],\n",
       "           [2.8791e-01, 1.5852e-02, 3.5773e-01, 5.6005e-01, 1.5695e-01,\n",
       "            9.4516e-01, 2.2983e-01, 4.2556e-01, 1.9367e-01, 8.7513e-01,\n",
       "            4.2679e-01, 3.0903e-01, 6.4261e-02, 6.6727e-01, 5.3934e-01,\n",
       "            1.9431e-01, 3.9854e-01, 6.2268e-01, 3.3125e-01, 4.2123e-01,\n",
       "            5.4105e-01, 3.0867e-01, 4.8531e-02, 8.0620e-01, 4.1951e-01,\n",
       "            3.0322e-01, 8.4610e-01, 1.9057e-01],\n",
       "           [8.7629e-01, 7.4174e-01, 3.3378e-01, 9.6390e-01, 8.7857e-01,\n",
       "            6.0878e-01, 1.6112e-02, 5.4179e-01, 1.1672e-01, 6.9805e-01,\n",
       "            3.2463e-01, 2.4104e-01, 8.9434e-01, 6.2652e-01, 9.2040e-01,\n",
       "            5.1733e-01, 1.3116e-02, 2.5807e-02, 8.0936e-02, 1.8036e-03,\n",
       "            2.9468e-01, 4.0956e-01, 4.4397e-02, 9.1977e-01, 6.5492e-01,\n",
       "            6.1428e-01, 6.0980e-01, 7.0004e-01],\n",
       "           [1.7377e-01, 5.7506e-01, 3.4107e-01, 5.4008e-01, 8.5611e-01,\n",
       "            6.6795e-01, 7.8650e-01, 3.8234e-02, 5.7963e-01, 5.4104e-01,\n",
       "            1.0381e-01, 8.0619e-01, 3.2633e-02, 8.9311e-01, 8.1917e-01,\n",
       "            9.2658e-02, 8.4379e-01, 2.4597e-01, 4.4542e-01, 5.0129e-01,\n",
       "            8.5246e-01, 8.4507e-01, 1.0687e-01, 3.5754e-01, 1.9234e-01,\n",
       "            8.6744e-01, 3.2211e-01, 1.7010e-01],\n",
       "           [7.5787e-01, 8.3704e-01, 7.5842e-03, 9.4159e-01, 7.6485e-01,\n",
       "            2.2565e-02, 2.6767e-01, 6.3468e-01, 3.8717e-01, 2.4142e-01,\n",
       "            2.8849e-01, 3.4518e-01, 8.6990e-01, 6.7365e-01, 6.2609e-01,\n",
       "            8.9719e-01, 3.4141e-01, 7.9935e-01, 8.1658e-01, 3.3716e-01,\n",
       "            6.7615e-01, 2.6426e-01, 6.0139e-01, 1.4154e-02, 2.8787e-01,\n",
       "            8.9292e-01, 6.4297e-01, 2.1603e-01],\n",
       "           [6.3455e-01, 9.4126e-01, 1.1265e-03, 4.7218e-01, 1.0081e-01,\n",
       "            8.2623e-01, 6.0354e-01, 5.7542e-01, 6.9486e-01, 4.7009e-01,\n",
       "            8.0075e-01, 6.4861e-02, 1.5266e-01, 6.9569e-01, 8.2294e-01,\n",
       "            1.5600e-01, 6.7583e-01, 2.6590e-02, 8.8311e-01, 6.4001e-01,\n",
       "            2.6929e-01, 9.4078e-01, 4.2349e-01, 9.4180e-01, 9.9998e-01,\n",
       "            9.2042e-01, 6.3375e-01, 5.9808e-01],\n",
       "           [6.2183e-01, 8.9157e-01, 8.8377e-01, 3.9120e-01, 9.0945e-01,\n",
       "            7.6391e-01, 8.6145e-01, 2.5452e-01, 9.0842e-01, 3.2602e-01,\n",
       "            7.0719e-01, 8.6769e-01, 9.2014e-01, 7.3677e-01, 2.1334e-01,\n",
       "            5.4471e-02, 6.1605e-01, 7.2016e-01, 3.3732e-01, 2.6939e-01,\n",
       "            7.6864e-01, 7.5493e-01, 1.5753e-01, 3.9768e-01, 7.6986e-01,\n",
       "            6.1235e-01, 1.0709e-01, 3.3190e-01],\n",
       "           [4.5918e-01, 9.3703e-01, 6.1227e-01, 1.7772e-01, 5.6453e-01,\n",
       "            3.8117e-01, 1.5189e-01, 6.0626e-01, 4.3029e-01, 4.9516e-01,\n",
       "            3.8328e-01, 8.8018e-01, 8.8955e-01, 5.3999e-01, 1.3064e-02,\n",
       "            6.5859e-01, 7.0861e-01, 9.6711e-01, 8.3386e-01, 3.3237e-01,\n",
       "            1.5474e-01, 2.4205e-01, 1.6745e-01, 5.1979e-01, 1.1139e-01,\n",
       "            7.9797e-01, 5.7386e-01, 4.3395e-01],\n",
       "           [9.8192e-01, 4.3044e-01, 4.6047e-01, 8.0525e-01, 8.6984e-01,\n",
       "            7.7376e-01, 6.3944e-03, 7.8186e-01, 7.8262e-01, 4.1725e-01,\n",
       "            8.1947e-01, 6.4964e-01, 1.3960e-01, 6.9273e-01, 2.9980e-01,\n",
       "            5.1635e-01, 1.2316e-01, 2.0164e-01, 2.6368e-01, 8.8421e-02,\n",
       "            2.4738e-01, 4.7938e-01, 9.9941e-01, 1.6949e-01, 2.8386e-01,\n",
       "            8.6211e-01, 8.1993e-01, 3.7694e-01],\n",
       "           [5.7368e-01, 6.5014e-01, 1.9867e-01, 1.8198e-01, 5.6233e-01,\n",
       "            6.2726e-01, 3.6823e-01, 4.4799e-01, 3.4199e-01, 2.3240e-01,\n",
       "            5.1228e-01, 2.6243e-02, 8.9379e-01, 2.5388e-01, 6.2370e-01,\n",
       "            5.1897e-01, 7.9191e-01, 1.0565e-01, 9.7241e-01, 4.2530e-01,\n",
       "            1.6386e-01, 9.2451e-01, 2.8362e-01, 5.4994e-01, 6.0538e-01,\n",
       "            4.3140e-01, 7.8073e-01, 2.1640e-01],\n",
       "           [4.9327e-01, 2.5305e-01, 3.7792e-01, 4.7661e-01, 3.4409e-01,\n",
       "            7.3863e-01, 1.0747e-01, 5.1260e-01, 2.8144e-01, 9.8136e-01,\n",
       "            8.1800e-01, 4.7845e-01, 7.4223e-03, 6.1656e-01, 5.8487e-01,\n",
       "            7.2119e-02, 8.4791e-01, 9.3044e-01, 4.8489e-01, 4.4122e-01,\n",
       "            7.2324e-01, 2.4718e-01, 8.2263e-01, 4.8058e-01, 1.7039e-01,\n",
       "            1.2876e-01, 1.2795e-01, 6.0824e-01],\n",
       "           [3.7622e-01, 5.7330e-01, 9.0385e-03, 4.0547e-01, 8.0009e-01,\n",
       "            9.7890e-01, 7.4801e-01, 1.5855e-01, 1.8494e-01, 9.0666e-01,\n",
       "            7.5496e-01, 6.3328e-02, 5.1588e-02, 5.7926e-01, 5.0123e-03,\n",
       "            1.6533e-01, 4.1821e-01, 7.5493e-01, 9.4320e-03, 3.4300e-01,\n",
       "            6.2979e-01, 4.4159e-01, 6.1879e-01, 2.4951e-04, 2.5444e-01,\n",
       "            8.7172e-01, 8.2836e-01, 7.4734e-01],\n",
       "           [9.6214e-01, 4.5468e-01, 1.1970e-01, 8.6322e-01, 8.8426e-01,\n",
       "            8.6845e-01, 4.3118e-02, 1.9135e-01, 8.6274e-01, 7.6140e-01,\n",
       "            6.9093e-01, 6.4893e-01, 9.3818e-01, 9.1418e-01, 5.9911e-01,\n",
       "            1.6258e-01, 9.3444e-02, 6.9024e-01, 7.5027e-01, 1.1336e-03,\n",
       "            8.1407e-01, 2.2975e-01, 7.2113e-01, 3.8769e-01, 8.1078e-02,\n",
       "            4.8465e-01, 9.7219e-01, 5.4891e-01],\n",
       "           [8.5395e-01, 7.2950e-01, 8.8257e-02, 8.2298e-01, 6.4778e-01,\n",
       "            7.2572e-01, 3.5610e-01, 7.5699e-01, 6.1427e-02, 6.6222e-01,\n",
       "            6.9542e-01, 8.7318e-01, 4.3768e-01, 7.0363e-01, 8.4282e-01,\n",
       "            6.5279e-01, 6.3766e-01, 4.0471e-01, 1.2160e-01, 2.2077e-01,\n",
       "            5.3613e-01, 1.4355e-01, 5.4253e-01, 1.6775e-01, 7.8680e-01,\n",
       "            2.1984e-01, 3.8321e-01, 6.8770e-01],\n",
       "           [1.9297e-01, 4.2082e-01, 5.7376e-01, 3.6922e-01, 1.7702e-01,\n",
       "            8.9766e-01, 2.4803e-01, 9.4756e-01, 9.3082e-01, 3.0861e-01,\n",
       "            5.1495e-01, 5.1007e-02, 7.5759e-02, 5.7646e-01, 1.2615e-01,\n",
       "            5.8257e-01, 4.3758e-01, 4.7246e-01, 4.0435e-01, 3.9040e-02,\n",
       "            2.8110e-01, 9.9877e-01, 6.7126e-02, 4.0561e-01, 4.4525e-01,\n",
       "            3.5490e-01, 2.6047e-01, 4.0280e-02],\n",
       "           [4.5809e-01, 5.8372e-02, 8.4267e-01, 9.9291e-01, 2.8817e-01,\n",
       "            3.0175e-01, 5.2244e-01, 5.2429e-01, 8.7607e-02, 6.4787e-01,\n",
       "            6.4967e-01, 6.5494e-01, 6.9921e-01, 9.2921e-01, 5.5224e-01,\n",
       "            5.2270e-01, 2.0891e-01, 3.4228e-01, 1.5239e-01, 5.4937e-01,\n",
       "            4.2588e-01, 4.5302e-01, 7.8757e-01, 2.5202e-01, 6.9135e-01,\n",
       "            1.1683e-01, 3.6856e-01, 3.7734e-01],\n",
       "           [6.8736e-01, 5.3148e-01, 6.7961e-01, 1.5196e-01, 3.2880e-01,\n",
       "            3.4850e-01, 5.6677e-02, 2.1046e-01, 5.2884e-01, 8.9568e-02,\n",
       "            3.2402e-01, 2.9145e-01, 5.0004e-01, 5.6499e-01, 5.3091e-01,\n",
       "            3.1082e-01, 9.6605e-01, 2.5888e-01, 9.2340e-01, 1.4378e-01,\n",
       "            1.4308e-01, 3.6833e-01, 5.0420e-02, 7.8410e-01, 6.3824e-02,\n",
       "            4.3711e-01, 5.9455e-02, 2.1684e-01],\n",
       "           [4.0882e-02, 1.3162e-01, 7.5926e-01, 4.2265e-01, 9.4083e-01,\n",
       "            7.5095e-01, 6.0130e-02, 2.4557e-01, 1.2286e-01, 4.5004e-01,\n",
       "            9.5280e-01, 7.9069e-01, 5.0344e-01, 5.3670e-01, 1.0449e-01,\n",
       "            1.5763e-01, 5.7086e-02, 3.3233e-01, 6.0603e-01, 4.3025e-01,\n",
       "            4.2467e-01, 3.8228e-01, 7.4045e-02, 7.9135e-01, 9.2852e-01,\n",
       "            8.6348e-02, 1.2372e-01, 8.4260e-01],\n",
       "           [9.1534e-01, 8.7943e-01, 7.1908e-01, 3.3113e-01, 1.1128e-01,\n",
       "            8.2189e-01, 8.0029e-01, 7.0796e-01, 4.1805e-01, 1.3551e-01,\n",
       "            4.2487e-01, 5.9749e-01, 2.7891e-01, 2.4385e-01, 7.8703e-03,\n",
       "            4.1201e-01, 9.7325e-01, 1.5821e-02, 7.0077e-01, 2.5264e-01,\n",
       "            5.9233e-01, 3.3002e-01, 8.9139e-01, 9.9417e-01, 9.5053e-01,\n",
       "            5.7159e-01, 7.4608e-01, 1.9965e-01],\n",
       "           [2.8289e-01, 9.0399e-01, 8.7149e-01, 7.3253e-02, 2.4847e-01,\n",
       "            2.7189e-01, 2.1673e-01, 4.0974e-01, 6.4219e-01, 1.8078e-01,\n",
       "            3.3025e-01, 2.0936e-01, 9.7047e-01, 2.8616e-01, 9.7064e-01,\n",
       "            4.6759e-02, 3.7931e-01, 6.3408e-01, 5.4364e-01, 8.1571e-01,\n",
       "            5.0313e-02, 6.8535e-01, 2.6999e-01, 7.5207e-01, 2.2268e-01,\n",
       "            2.8706e-01, 8.7156e-01, 6.4219e-02],\n",
       "           [1.9233e-01, 7.2466e-01, 7.8049e-01, 3.9930e-01, 2.9335e-01,\n",
       "            9.5369e-01, 7.1640e-01, 7.8441e-01, 5.2391e-01, 1.8648e-01,\n",
       "            6.8082e-02, 8.0908e-01, 8.8289e-02, 8.2839e-01, 7.2088e-01,\n",
       "            6.4865e-01, 8.5921e-01, 6.3578e-01, 9.4352e-01, 7.4318e-01,\n",
       "            7.3484e-01, 9.9813e-01, 8.2712e-01, 6.9244e-01, 9.6343e-01,\n",
       "            8.5702e-01, 6.1946e-01, 5.4085e-01],\n",
       "           [4.0531e-01, 5.2720e-01, 3.3396e-01, 8.9217e-01, 8.6997e-01,\n",
       "            2.0745e-01, 5.2296e-01, 3.1199e-01, 6.4832e-02, 5.9145e-01,\n",
       "            8.5163e-01, 3.0466e-02, 5.3407e-01, 5.9832e-01, 3.0256e-01,\n",
       "            8.8809e-01, 5.0361e-02, 6.1576e-01, 4.3274e-01, 4.9534e-01,\n",
       "            6.0130e-01, 1.0003e-01, 4.2944e-01, 6.4006e-01, 3.6759e-01,\n",
       "            3.9526e-01, 4.4912e-01, 3.4198e-01],\n",
       "           [1.1031e-01, 6.0018e-01, 2.9946e-01, 7.1631e-01, 5.0435e-01,\n",
       "            9.8407e-01, 4.6412e-01, 5.8971e-01, 9.2606e-02, 1.4735e-01,\n",
       "            5.9511e-01, 6.8203e-01, 2.9511e-01, 1.6807e-01, 2.7003e-01,\n",
       "            2.4720e-01, 6.9461e-01, 9.0241e-02, 4.3918e-02, 8.4085e-01,\n",
       "            3.2465e-01, 8.0843e-01, 4.5701e-01, 6.2408e-01, 9.1021e-01,\n",
       "            8.1313e-02, 2.9880e-01, 2.7374e-01],\n",
       "           [5.0722e-01, 5.8840e-01, 3.1578e-01, 3.4598e-01, 7.2436e-01,\n",
       "            5.3945e-01, 1.0796e-02, 5.5655e-01, 2.4587e-01, 6.0529e-01,\n",
       "            8.7503e-01, 4.0947e-01, 6.8523e-01, 9.3086e-01, 8.6135e-01,\n",
       "            8.7815e-01, 7.1825e-01, 4.1327e-01, 6.8795e-02, 5.4688e-01,\n",
       "            5.2755e-01, 7.7641e-02, 5.5913e-01, 6.0360e-02, 6.3054e-01,\n",
       "            4.2609e-01, 4.3421e-01, 4.1080e-01],\n",
       "           [2.1773e-01, 7.4216e-01, 8.1930e-01, 3.4585e-01, 8.9335e-01,\n",
       "            9.2119e-01, 3.9022e-01, 3.6842e-01, 1.9782e-01, 1.0601e-01,\n",
       "            6.9669e-01, 2.8313e-01, 3.1790e-01, 5.9727e-01, 2.0677e-01,\n",
       "            3.7000e-01, 2.9896e-01, 8.0197e-01, 4.2912e-01, 7.0230e-02,\n",
       "            4.7322e-01, 5.8933e-01, 1.8374e-01, 1.4440e-01, 4.3090e-01,\n",
       "            5.3068e-01, 7.3703e-01, 5.5841e-01],\n",
       "           [8.1692e-01, 4.2885e-01, 8.6495e-01, 7.0274e-02, 9.7659e-01,\n",
       "            1.1202e-01, 5.5769e-01, 7.5380e-01, 7.5206e-01, 6.3776e-01,\n",
       "            9.7532e-02, 6.7670e-01, 7.8275e-01, 4.2325e-01, 9.3371e-01,\n",
       "            7.3011e-01, 3.6593e-01, 8.5747e-01, 6.6956e-01, 2.3026e-01,\n",
       "            3.9212e-01, 3.6903e-01, 3.0030e-01, 7.8206e-01, 1.0562e-01,\n",
       "            5.8246e-01, 6.3456e-01, 6.1749e-01]]]),\n",
       "  3),\n",
       " (tensor([[[6.6117e-01, 9.5430e-01, 7.2324e-01, 3.3377e-01, 4.9699e-01,\n",
       "            9.9084e-02, 9.5024e-01, 1.0020e-01, 2.5285e-01, 5.5883e-02,\n",
       "            5.3231e-01, 9.8725e-01, 4.9036e-02, 6.5294e-01, 2.9808e-01,\n",
       "            3.5116e-01, 9.9033e-01, 6.5641e-01, 2.4103e-01, 1.7823e-02,\n",
       "            1.4656e-01, 3.7553e-01, 2.8812e-01, 2.8515e-01, 5.3496e-01,\n",
       "            4.5616e-01, 2.8566e-01, 8.3816e-01],\n",
       "           [5.3190e-01, 2.2878e-02, 1.4735e-01, 1.2211e-01, 1.9458e-01,\n",
       "            3.1499e-01, 8.2639e-01, 7.5729e-01, 9.4508e-01, 2.9412e-01,\n",
       "            1.5778e-01, 6.8974e-01, 2.9989e-01, 8.4055e-01, 6.1791e-01,\n",
       "            2.4771e-01, 8.8542e-02, 3.4038e-01, 2.2806e-01, 1.4806e-01,\n",
       "            2.9623e-01, 1.5046e-01, 7.6477e-01, 1.6171e-01, 8.4960e-01,\n",
       "            2.2584e-01, 6.3076e-01, 7.9639e-01],\n",
       "           [1.5930e-01, 3.1604e-01, 8.9226e-01, 1.3669e-01, 4.1492e-01,\n",
       "            2.4580e-01, 8.8646e-01, 8.5376e-01, 8.5708e-01, 4.8669e-01,\n",
       "            5.2013e-01, 3.4112e-01, 3.6854e-01, 7.7755e-01, 7.1326e-01,\n",
       "            6.6825e-01, 3.3756e-01, 6.1444e-01, 3.3262e-01, 6.4515e-01,\n",
       "            7.4077e-01, 4.9708e-01, 2.5819e-01, 2.0168e-01, 1.8441e-01,\n",
       "            1.3771e-02, 5.2656e-01, 1.0552e-02],\n",
       "           [5.7241e-01, 1.2928e-02, 7.0194e-02, 5.9816e-01, 3.8081e-01,\n",
       "            3.8341e-01, 6.5924e-01, 2.1946e-01, 7.2119e-01, 3.0130e-01,\n",
       "            6.9104e-01, 6.3867e-01, 2.3434e-01, 8.8195e-01, 7.9052e-01,\n",
       "            2.7616e-01, 8.5892e-01, 1.7004e-01, 3.8307e-01, 5.4723e-01,\n",
       "            2.5152e-01, 4.3220e-01, 7.4278e-01, 4.4376e-01, 9.8785e-01,\n",
       "            6.3259e-01, 3.3934e-01, 5.2321e-01],\n",
       "           [6.6124e-01, 2.8780e-01, 7.6571e-02, 4.0609e-01, 8.9780e-01,\n",
       "            6.4632e-01, 8.1583e-01, 9.9632e-01, 6.2508e-01, 4.8104e-01,\n",
       "            3.7329e-01, 4.8963e-01, 9.7341e-01, 6.6169e-01, 2.3500e-01,\n",
       "            5.7946e-02, 5.9619e-01, 9.1510e-01, 5.3724e-02, 5.0510e-01,\n",
       "            3.8846e-01, 4.2466e-01, 8.5498e-01, 4.2668e-01, 4.7666e-01,\n",
       "            4.6169e-01, 6.7602e-01, 6.8844e-02],\n",
       "           [1.5565e-01, 9.2889e-01, 3.3009e-01, 8.6766e-01, 3.4280e-01,\n",
       "            4.1257e-01, 7.4994e-01, 3.5605e-01, 7.2073e-01, 6.5778e-02,\n",
       "            3.7985e-02, 7.2239e-01, 5.6561e-01, 9.5481e-01, 7.5956e-01,\n",
       "            2.2471e-01, 5.1433e-01, 3.2938e-01, 1.1816e-01, 4.3322e-02,\n",
       "            9.7042e-01, 5.5233e-01, 8.2045e-01, 8.4734e-01, 5.6928e-01,\n",
       "            9.4134e-01, 4.8015e-01, 2.3359e-01],\n",
       "           [6.2343e-01, 7.7623e-01, 1.5876e-02, 5.7910e-02, 8.3686e-01,\n",
       "            6.2548e-01, 4.2029e-01, 7.9455e-01, 2.4155e-01, 5.7214e-01,\n",
       "            8.2110e-01, 3.1842e-01, 7.4557e-01, 9.8504e-01, 7.9807e-02,\n",
       "            9.9393e-01, 3.0535e-01, 6.9881e-01, 6.8718e-01, 9.0304e-01,\n",
       "            4.7991e-01, 9.9873e-01, 8.3004e-01, 4.3484e-01, 2.3740e-01,\n",
       "            9.3191e-01, 4.1562e-04, 6.2080e-01],\n",
       "           [3.8926e-01, 4.3873e-01, 9.6786e-01, 4.4803e-01, 1.8661e-02,\n",
       "            1.4826e-01, 8.1798e-01, 3.6915e-01, 4.0307e-01, 6.1022e-01,\n",
       "            1.3983e-01, 8.6167e-01, 8.4324e-01, 1.7641e-01, 6.2351e-01,\n",
       "            6.7127e-01, 5.5714e-01, 7.4534e-02, 2.8816e-01, 1.7329e-01,\n",
       "            7.7216e-01, 1.4365e-01, 8.1433e-01, 6.3130e-01, 5.8880e-02,\n",
       "            7.4055e-01, 5.0463e-01, 5.4853e-01],\n",
       "           [2.9846e-01, 3.5522e-01, 3.2052e-01, 9.1728e-01, 8.8491e-01,\n",
       "            4.2779e-01, 2.8760e-01, 8.4045e-01, 1.2306e-01, 4.6412e-01,\n",
       "            5.1189e-01, 7.9190e-01, 4.0695e-01, 6.2320e-01, 6.0699e-01,\n",
       "            4.9668e-01, 8.0928e-03, 9.0124e-01, 4.9368e-01, 4.4707e-01,\n",
       "            5.4257e-01, 5.1617e-02, 8.2728e-02, 4.5629e-01, 7.4458e-01,\n",
       "            8.0267e-01, 5.2143e-01, 1.8856e-01],\n",
       "           [4.8660e-01, 1.4787e-01, 7.6682e-01, 8.5599e-01, 4.4359e-01,\n",
       "            9.5640e-01, 4.6438e-01, 3.1376e-01, 7.4155e-01, 8.8577e-01,\n",
       "            6.6207e-01, 8.9623e-01, 4.8051e-01, 5.1191e-03, 4.5159e-01,\n",
       "            3.4298e-01, 2.5035e-01, 5.7906e-01, 2.7333e-01, 3.2903e-01,\n",
       "            7.4657e-01, 3.4753e-01, 5.6181e-01, 6.0648e-01, 8.9536e-01,\n",
       "            3.6587e-02, 9.5267e-02, 6.9590e-01],\n",
       "           [6.9049e-01, 9.1549e-01, 6.8602e-01, 1.7150e-01, 3.0105e-01,\n",
       "            3.9778e-03, 3.6043e-01, 2.9533e-01, 8.2061e-01, 4.2875e-01,\n",
       "            9.7790e-02, 1.0713e-01, 2.7409e-02, 1.1245e-01, 4.7070e-01,\n",
       "            9.6920e-02, 2.0218e-02, 9.1276e-01, 8.5797e-01, 9.7091e-01,\n",
       "            2.5030e-01, 4.9994e-01, 5.8631e-01, 8.6706e-01, 1.4310e-01,\n",
       "            1.5968e-01, 4.8017e-01, 7.8781e-01],\n",
       "           [7.7641e-01, 4.7957e-01, 4.3907e-01, 1.8797e-02, 9.1306e-01,\n",
       "            7.1462e-01, 4.7602e-01, 1.6818e-01, 4.6440e-01, 6.0577e-01,\n",
       "            7.0932e-01, 2.5227e-01, 5.4946e-01, 3.9027e-01, 1.3749e-01,\n",
       "            6.8078e-01, 7.8809e-03, 5.8424e-01, 3.8860e-01, 2.3622e-01,\n",
       "            7.0236e-01, 7.0912e-01, 1.8562e-02, 7.4739e-01, 6.6268e-01,\n",
       "            7.0755e-01, 9.3283e-02, 9.0801e-01],\n",
       "           [9.3048e-01, 4.6942e-01, 8.3783e-01, 9.4446e-01, 5.4191e-01,\n",
       "            2.4322e-01, 7.5446e-02, 3.1765e-01, 7.5495e-01, 9.5653e-01,\n",
       "            2.3686e-03, 4.9643e-01, 6.5769e-01, 6.4502e-01, 7.3497e-01,\n",
       "            5.7086e-02, 6.9620e-02, 8.2408e-01, 3.2786e-01, 1.5466e-01,\n",
       "            7.1374e-01, 8.3194e-01, 3.5509e-01, 5.2613e-01, 3.8587e-02,\n",
       "            7.5207e-01, 4.9846e-01, 5.1419e-01],\n",
       "           [3.3304e-01, 3.8618e-01, 3.5817e-01, 5.2352e-01, 4.6643e-01,\n",
       "            9.9163e-01, 2.5965e-01, 8.3761e-01, 4.0846e-02, 9.3539e-01,\n",
       "            8.6350e-01, 7.3135e-02, 5.5548e-01, 4.0204e-01, 7.2037e-01,\n",
       "            5.5400e-01, 2.2478e-01, 7.8744e-01, 7.7010e-01, 2.8777e-01,\n",
       "            8.9843e-01, 5.3071e-02, 1.8072e-01, 9.1759e-01, 6.3346e-02,\n",
       "            5.1260e-01, 9.5230e-01, 7.0244e-01],\n",
       "           [1.5085e-01, 9.9235e-01, 5.1995e-01, 2.3840e-01, 4.6796e-01,\n",
       "            6.5790e-01, 8.9793e-01, 3.6340e-01, 7.7241e-01, 7.4448e-01,\n",
       "            5.7455e-01, 8.4647e-01, 8.2048e-01, 5.6311e-01, 8.0574e-01,\n",
       "            9.0161e-01, 2.9764e-01, 3.0073e-01, 5.2418e-01, 4.2461e-01,\n",
       "            9.2640e-01, 3.6303e-01, 9.3452e-01, 6.3991e-01, 4.2712e-01,\n",
       "            1.5572e-01, 2.0017e-02, 4.9683e-01],\n",
       "           [2.4540e-02, 7.3612e-01, 1.9936e-01, 9.4984e-01, 5.1451e-01,\n",
       "            5.7159e-02, 3.9933e-01, 1.8921e-01, 1.7231e-01, 4.2141e-01,\n",
       "            6.5900e-02, 4.6664e-01, 2.9640e-01, 2.9279e-01, 8.9754e-01,\n",
       "            7.6046e-01, 7.2030e-01, 4.4734e-01, 7.4549e-01, 5.7294e-01,\n",
       "            9.5155e-01, 6.7659e-01, 5.2086e-01, 9.9103e-01, 2.7871e-01,\n",
       "            2.8075e-01, 8.7815e-01, 1.8056e-01],\n",
       "           [2.4778e-01, 8.3378e-01, 3.2301e-01, 5.1701e-02, 3.9321e-03,\n",
       "            2.2287e-01, 8.3260e-02, 8.6151e-01, 9.9495e-01, 9.5122e-01,\n",
       "            3.2889e-01, 1.6800e-01, 4.0203e-01, 6.8123e-02, 4.6291e-02,\n",
       "            7.0711e-01, 7.6642e-01, 5.6859e-01, 5.0373e-02, 3.6696e-01,\n",
       "            9.7587e-01, 7.1877e-01, 3.8613e-01, 1.7439e-01, 8.0174e-01,\n",
       "            7.8552e-01, 9.8308e-01, 4.9972e-02],\n",
       "           [8.1919e-01, 3.6771e-01, 7.8077e-01, 9.5790e-01, 5.2142e-01,\n",
       "            1.5028e-01, 3.7948e-02, 6.6588e-01, 9.1181e-01, 1.8352e-02,\n",
       "            8.9074e-02, 3.0717e-01, 2.3260e-01, 5.1850e-01, 8.5732e-01,\n",
       "            8.8951e-01, 7.6946e-01, 7.5273e-02, 6.1310e-01, 1.7667e-01,\n",
       "            5.5817e-01, 3.2255e-01, 7.9932e-01, 1.2177e-01, 1.7183e-01,\n",
       "            7.8216e-01, 2.9584e-01, 3.8917e-01],\n",
       "           [7.9468e-01, 6.9528e-01, 5.8003e-01, 2.6877e-02, 7.8979e-01,\n",
       "            5.8979e-01, 8.2857e-01, 2.9026e-01, 6.1350e-01, 8.5902e-01,\n",
       "            3.2510e-02, 2.1435e-01, 2.5375e-01, 8.7848e-01, 4.0762e-01,\n",
       "            9.4037e-03, 4.3913e-01, 2.0771e-01, 7.0245e-02, 9.5018e-01,\n",
       "            8.0438e-01, 4.9819e-03, 1.5625e-01, 3.3849e-01, 7.3328e-01,\n",
       "            3.9668e-01, 4.6272e-01, 6.9315e-01],\n",
       "           [2.1165e-01, 9.5472e-02, 3.3687e-01, 9.5233e-01, 2.6767e-01,\n",
       "            6.3533e-01, 6.3397e-01, 8.7996e-02, 8.3628e-01, 5.6841e-01,\n",
       "            4.4676e-01, 3.9596e-01, 7.0991e-01, 5.3955e-02, 6.9746e-01,\n",
       "            4.9037e-01, 3.5526e-01, 6.8150e-01, 4.9737e-01, 8.4335e-01,\n",
       "            6.5101e-01, 1.8147e-01, 1.1481e-02, 1.1405e-01, 5.7640e-02,\n",
       "            2.9788e-01, 9.7987e-01, 2.1389e-01],\n",
       "           [2.0140e-01, 1.3365e-01, 8.2264e-02, 7.1638e-01, 4.6868e-01,\n",
       "            6.9432e-02, 6.2065e-01, 2.7855e-01, 8.6277e-01, 6.2271e-01,\n",
       "            9.2064e-01, 2.2854e-01, 7.8006e-01, 2.5234e-03, 2.4884e-01,\n",
       "            7.2922e-02, 7.2019e-01, 8.9761e-01, 9.8054e-01, 6.2423e-01,\n",
       "            4.1719e-01, 4.3286e-01, 3.5193e-01, 3.9368e-01, 9.3188e-01,\n",
       "            4.1042e-01, 3.7557e-01, 1.7150e-01],\n",
       "           [1.5426e-01, 9.8205e-01, 3.9298e-01, 3.4871e-02, 1.0380e-01,\n",
       "            5.2201e-01, 5.6273e-01, 4.0448e-01, 5.4239e-02, 3.9896e-01,\n",
       "            9.9057e-01, 9.3544e-01, 1.7729e-01, 9.1920e-01, 1.4402e-01,\n",
       "            2.6595e-01, 4.7939e-01, 7.7931e-01, 3.9046e-01, 8.5734e-02,\n",
       "            8.2843e-01, 5.4196e-01, 6.8028e-01, 6.2519e-01, 7.5781e-01,\n",
       "            4.1639e-01, 7.9718e-01, 9.4273e-01],\n",
       "           [1.0281e-02, 6.3019e-01, 1.3633e-01, 4.4880e-01, 8.5232e-01,\n",
       "            4.4966e-01, 9.5661e-01, 3.7208e-01, 2.7088e-01, 3.0413e-01,\n",
       "            7.2444e-01, 5.5870e-01, 6.1420e-01, 5.3011e-01, 4.1240e-01,\n",
       "            3.4437e-01, 1.2486e-01, 9.2193e-01, 8.2668e-01, 2.1884e-01,\n",
       "            2.9279e-01, 4.1701e-02, 2.2651e-01, 5.5194e-01, 7.1988e-01,\n",
       "            3.5452e-02, 8.7715e-01, 3.5514e-01],\n",
       "           [2.6733e-01, 9.6725e-01, 6.9942e-01, 8.9478e-01, 9.7955e-01,\n",
       "            6.1166e-01, 7.4221e-02, 3.3508e-01, 5.4934e-01, 1.7052e-01,\n",
       "            5.7198e-01, 1.3700e-01, 2.3226e-03, 2.9116e-01, 9.4146e-01,\n",
       "            4.6205e-01, 2.1825e-01, 1.2786e-01, 9.2913e-01, 8.6241e-01,\n",
       "            3.2197e-02, 9.6101e-01, 4.5350e-01, 6.4189e-01, 3.9885e-01,\n",
       "            6.2289e-01, 5.8688e-01, 5.4115e-01],\n",
       "           [7.8180e-01, 4.5046e-01, 8.6702e-01, 8.7410e-01, 5.5757e-01,\n",
       "            6.0588e-01, 3.7356e-01, 7.9506e-01, 1.9835e-01, 9.7897e-01,\n",
       "            4.6189e-01, 8.3489e-02, 6.5058e-01, 2.1644e-01, 3.1240e-01,\n",
       "            7.3408e-01, 5.5727e-01, 4.7135e-01, 3.5524e-01, 3.4959e-02,\n",
       "            9.1574e-01, 5.3215e-02, 3.5246e-01, 2.3489e-01, 6.2221e-01,\n",
       "            5.1781e-01, 2.6472e-01, 4.6392e-01],\n",
       "           [7.9033e-01, 3.4647e-01, 5.2770e-01, 9.6383e-01, 5.4983e-02,\n",
       "            5.0581e-01, 6.4940e-01, 7.5140e-01, 1.7962e-01, 8.4511e-01,\n",
       "            2.7009e-02, 1.3593e-01, 7.2868e-01, 7.2913e-01, 9.1516e-01,\n",
       "            4.5024e-02, 5.8173e-02, 1.6203e-02, 9.4396e-01, 7.9702e-01,\n",
       "            1.6652e-01, 1.1725e-01, 3.6166e-01, 6.2011e-01, 9.6336e-01,\n",
       "            1.5359e-01, 6.6556e-01, 3.6897e-01],\n",
       "           [6.0440e-03, 2.4187e-01, 2.5653e-01, 1.1432e-01, 8.3811e-02,\n",
       "            3.5677e-01, 2.7750e-01, 3.2158e-01, 2.2871e-01, 9.3690e-01,\n",
       "            7.7653e-01, 5.6210e-01, 4.9444e-01, 9.2138e-01, 8.7105e-01,\n",
       "            5.5256e-01, 9.7753e-01, 3.5790e-01, 1.9513e-01, 3.9560e-01,\n",
       "            4.0466e-01, 1.9111e-01, 7.9276e-01, 8.4356e-01, 5.7910e-01,\n",
       "            3.0073e-01, 7.2996e-02, 5.8395e-01],\n",
       "           [2.2075e-01, 3.8631e-01, 7.2286e-01, 1.0233e-01, 5.5814e-01,\n",
       "            3.0306e-01, 9.4102e-01, 2.5674e-01, 5.5747e-02, 9.7351e-01,\n",
       "            9.1305e-01, 6.1315e-01, 9.7316e-01, 6.1715e-01, 7.5524e-01,\n",
       "            1.4983e-01, 2.8019e-01, 3.7187e-01, 4.3991e-01, 4.4523e-01,\n",
       "            2.5803e-01, 8.2025e-01, 6.6396e-01, 5.4322e-01, 2.5029e-01,\n",
       "            9.0987e-01, 5.6911e-01, 8.1020e-01]]]),\n",
       "  3),\n",
       " (tensor([[[0.6204, 0.1720, 0.8448, 0.4961, 0.7008, 0.8719, 0.6782, 0.3935,\n",
       "            0.2419, 0.1717, 0.7337, 0.8413, 0.2325, 0.2227, 0.1910, 0.1214,\n",
       "            0.4114, 0.7925, 0.4956, 0.5522, 0.0316, 0.0722, 0.0590, 0.4920,\n",
       "            0.7512, 0.2603, 0.2049, 0.9549],\n",
       "           [0.3558, 0.6234, 0.9582, 0.8802, 0.1484, 0.2568, 0.5249, 0.6771,\n",
       "            0.2000, 0.8964, 0.6251, 0.5834, 0.4839, 0.9956, 0.5789, 0.1552,\n",
       "            0.3866, 0.0111, 0.5750, 0.4857, 0.5502, 0.4019, 0.0444, 0.8313,\n",
       "            0.8046, 0.8205, 0.2047, 0.1867],\n",
       "           [0.0982, 0.6306, 0.2752, 0.1350, 0.0595, 0.9039, 0.7736, 0.7304,\n",
       "            0.9205, 0.3977, 0.0791, 0.8467, 0.2722, 0.6621, 0.9102, 0.3421,\n",
       "            0.7316, 0.8361, 0.9049, 0.7587, 0.8085, 0.4349, 0.7533, 0.0039,\n",
       "            0.2289, 0.1221, 0.2191, 0.3067],\n",
       "           [0.4056, 0.9884, 0.0548, 0.7068, 0.1799, 0.1992, 0.1835, 0.9228,\n",
       "            0.2918, 0.7088, 0.4051, 0.1305, 0.7981, 0.6422, 0.9533, 0.1092,\n",
       "            0.0627, 0.3853, 0.9186, 0.0272, 0.5346, 0.6872, 0.8852, 0.5937,\n",
       "            0.8058, 0.3990, 0.1763, 0.3723],\n",
       "           [0.3750, 0.1876, 0.3302, 0.1183, 0.7805, 0.2536, 0.0612, 0.9657,\n",
       "            0.7626, 0.7711, 0.5022, 0.1120, 0.8901, 0.6469, 0.6036, 0.2906,\n",
       "            0.0833, 0.6197, 0.7576, 0.9402, 0.2509, 0.8693, 0.9410, 0.9785,\n",
       "            0.4006, 0.4054, 0.4128, 0.2243],\n",
       "           [0.5802, 0.7035, 0.9278, 0.8229, 0.5517, 0.7283, 0.8709, 0.7765,\n",
       "            0.9182, 0.5722, 0.1874, 0.4235, 0.8763, 0.3085, 0.6621, 0.5592,\n",
       "            0.0583, 0.9444, 0.6489, 0.7298, 0.6863, 0.5575, 0.7944, 0.0056,\n",
       "            0.3410, 0.6664, 0.0804, 0.3361],\n",
       "           [0.7703, 0.3750, 0.3243, 0.8268, 0.6803, 0.8525, 0.9602, 0.0322,\n",
       "            0.0139, 0.6387, 0.1214, 0.2905, 0.6756, 0.7408, 0.1623, 0.9923,\n",
       "            0.9599, 0.5037, 0.8511, 0.6949, 0.5859, 0.9561, 0.7202, 0.3409,\n",
       "            0.8630, 0.3650, 0.9931, 0.8777],\n",
       "           [0.0802, 0.5597, 0.2713, 0.7800, 0.9743, 0.8089, 0.3383, 0.1545,\n",
       "            0.5110, 0.4207, 0.2000, 0.6252, 0.1949, 0.9577, 0.3704, 0.4468,\n",
       "            0.7680, 0.1533, 0.4944, 0.0381, 0.4118, 0.8563, 0.1316, 0.4134,\n",
       "            0.9622, 0.6402, 0.9992, 0.1805],\n",
       "           [0.9376, 0.9689, 0.1765, 0.5791, 0.1930, 0.7134, 0.6804, 0.1220,\n",
       "            0.7939, 0.8599, 0.0650, 0.9482, 0.9920, 0.9770, 0.6785, 0.8260,\n",
       "            0.2788, 0.6787, 0.3821, 0.3340, 0.2461, 0.2430, 0.0152, 0.7601,\n",
       "            0.0117, 0.6304, 0.6206, 0.0801],\n",
       "           [0.0828, 0.0543, 0.2215, 0.3391, 0.1527, 0.6631, 0.2053, 0.8746,\n",
       "            0.1252, 0.1524, 0.1053, 0.0833, 0.3992, 0.0992, 0.3538, 0.8329,\n",
       "            0.9696, 0.7438, 0.5062, 0.7625, 0.8122, 0.0786, 0.2156, 0.7302,\n",
       "            0.7702, 0.0966, 0.9471, 0.4078],\n",
       "           [0.6285, 0.1671, 0.6294, 0.0507, 0.0761, 0.5760, 0.9605, 0.0588,\n",
       "            0.9392, 0.2959, 0.8062, 0.2296, 0.1973, 0.5259, 0.2166, 0.7305,\n",
       "            0.7609, 0.8718, 0.9159, 0.1679, 0.5902, 0.4612, 0.4333, 0.9554,\n",
       "            0.8348, 0.0980, 0.5580, 0.8272],\n",
       "           [0.7539, 0.7060, 0.3855, 0.5957, 0.7944, 0.1020, 0.1173, 0.2202,\n",
       "            0.1891, 0.3757, 0.9449, 0.0223, 0.0293, 0.1530, 0.9966, 0.4359,\n",
       "            0.3699, 0.2739, 0.4843, 0.5933, 0.6644, 0.9498, 0.5389, 0.4114,\n",
       "            0.4880, 0.3350, 0.2645, 0.2721],\n",
       "           [0.9435, 0.1293, 0.0016, 0.7461, 0.2645, 0.3626, 0.2081, 0.8830,\n",
       "            0.3083, 0.3342, 0.5699, 0.7502, 0.7962, 0.7461, 0.3406, 0.8562,\n",
       "            0.0611, 0.6416, 0.2700, 0.7908, 0.7864, 0.6972, 0.9846, 0.4990,\n",
       "            0.9933, 0.0458, 0.7221, 0.5960],\n",
       "           [0.0295, 0.5716, 0.6990, 0.8245, 0.2389, 0.2141, 0.5412, 0.9817,\n",
       "            0.8834, 0.6076, 0.5198, 0.6248, 0.0774, 0.6214, 0.3265, 0.9502,\n",
       "            0.3595, 0.3940, 0.3859, 0.5957, 0.4487, 0.2221, 0.9030, 0.5715,\n",
       "            0.4292, 0.3762, 0.8189, 0.7163],\n",
       "           [0.0407, 0.8267, 0.3953, 0.8556, 0.6351, 0.4306, 0.2382, 0.6437,\n",
       "            0.4539, 0.6072, 0.6303, 0.0433, 0.1703, 0.9359, 0.2907, 0.5866,\n",
       "            0.8848, 0.0719, 0.5337, 0.6649, 0.3028, 0.0935, 0.6674, 0.5109,\n",
       "            0.9382, 0.6614, 0.3482, 0.4194],\n",
       "           [0.6537, 0.1922, 0.3748, 0.2493, 0.9627, 0.2607, 0.7534, 0.2897,\n",
       "            0.1780, 0.6260, 0.2742, 0.3400, 0.6390, 0.5841, 0.1734, 0.3928,\n",
       "            0.5651, 0.8942, 0.0683, 0.9140, 0.1984, 0.5845, 0.5926, 0.8901,\n",
       "            0.9852, 0.4541, 0.7955, 0.3527],\n",
       "           [0.7422, 0.0825, 0.1732, 0.2226, 0.9036, 0.3302, 0.6692, 0.1756,\n",
       "            0.2065, 0.7788, 0.6879, 0.0174, 0.5975, 0.8793, 0.2188, 0.5917,\n",
       "            0.1516, 0.3018, 0.7830, 0.8643, 0.9828, 0.3509, 0.0871, 0.9802,\n",
       "            0.9537, 0.9492, 0.6815, 0.6138],\n",
       "           [0.0655, 0.8318, 0.0879, 0.4039, 0.6546, 0.2324, 0.5733, 0.5648,\n",
       "            0.1750, 0.0308, 0.5740, 0.2494, 0.6572, 0.6616, 0.8940, 0.3891,\n",
       "            0.4039, 0.4403, 0.4344, 0.2088, 0.5895, 0.6765, 0.0885, 0.4492,\n",
       "            0.1412, 0.5895, 0.4970, 0.2367],\n",
       "           [0.5587, 0.8928, 0.0508, 0.4711, 0.8927, 0.3829, 0.4849, 0.2300,\n",
       "            0.7379, 0.2310, 0.3634, 0.5510, 0.3634, 0.8728, 0.7623, 0.4130,\n",
       "            0.8406, 0.1653, 0.9540, 0.1023, 0.8257, 0.9522, 0.1334, 0.5072,\n",
       "            0.8530, 0.6130, 0.6640, 0.3432],\n",
       "           [0.9732, 0.1748, 0.0339, 0.1970, 0.7020, 0.4897, 0.4037, 0.6503,\n",
       "            0.3384, 0.7979, 0.2551, 0.2279, 0.7101, 0.7558, 0.7849, 0.5658,\n",
       "            0.2529, 0.9044, 0.9008, 0.7463, 0.5574, 0.1553, 0.0707, 0.9422,\n",
       "            0.8538, 0.2256, 0.4276, 0.4680],\n",
       "           [0.7079, 0.4781, 0.7807, 0.1979, 0.6015, 0.3375, 0.3794, 0.5833,\n",
       "            0.0902, 0.7693, 0.5000, 0.6781, 0.4850, 0.6479, 0.4236, 0.4942,\n",
       "            0.6620, 0.5076, 0.9787, 0.2999, 0.3365, 0.5372, 0.4401, 0.8460,\n",
       "            0.4409, 0.1162, 0.8729, 0.7969],\n",
       "           [0.2371, 0.7427, 0.9749, 0.5958, 0.3456, 0.4859, 0.8337, 0.8111,\n",
       "            0.4875, 0.5202, 0.8712, 0.3785, 0.6181, 0.2732, 0.7449, 0.8289,\n",
       "            0.4890, 0.6009, 0.0899, 0.8367, 0.2768, 0.4729, 0.9964, 0.4371,\n",
       "            0.1924, 0.8885, 0.9105, 0.3184],\n",
       "           [0.7390, 0.8242, 0.9336, 0.6163, 0.0917, 0.8809, 0.7432, 0.5844,\n",
       "            0.0232, 0.2982, 0.5833, 0.3901, 0.2889, 0.9430, 0.3411, 0.9930,\n",
       "            0.1109, 0.1614, 0.7698, 0.7388, 0.6580, 0.3643, 0.2084, 0.2531,\n",
       "            0.0086, 0.3159, 0.5035, 0.7457],\n",
       "           [0.0177, 0.5344, 0.7756, 0.0222, 0.5354, 0.6875, 0.5387, 0.6612,\n",
       "            0.2220, 0.9611, 0.0936, 0.0064, 0.6126, 0.4679, 0.9601, 0.3753,\n",
       "            0.4002, 0.0737, 0.1179, 0.5903, 0.4859, 0.4226, 0.6230, 0.3410,\n",
       "            0.4954, 0.5270, 0.6674, 0.7591],\n",
       "           [0.3477, 0.5488, 0.3420, 0.4267, 0.1953, 0.3738, 0.3208, 0.3503,\n",
       "            0.4670, 0.9110, 0.1120, 0.6416, 0.1963, 0.0605, 0.1954, 0.2136,\n",
       "            0.8027, 0.3475, 0.3808, 0.1077, 0.5160, 0.2634, 0.3565, 0.1350,\n",
       "            0.6663, 0.7703, 0.8660, 0.9006],\n",
       "           [0.7024, 0.8577, 0.9464, 0.9037, 0.0032, 0.8753, 0.8945, 0.0725,\n",
       "            0.8523, 0.0414, 0.3881, 0.1977, 0.0874, 0.2004, 0.4020, 0.2045,\n",
       "            0.3207, 0.1525, 0.3172, 0.3769, 0.2340, 0.7543, 0.9381, 0.7303,\n",
       "            0.5168, 0.2437, 0.7464, 0.5603],\n",
       "           [0.6980, 0.5214, 0.6625, 0.0749, 0.6464, 0.8205, 0.7926, 0.7144,\n",
       "            0.3191, 0.7575, 0.1316, 0.4872, 0.8887, 0.0236, 0.9874, 0.6582,\n",
       "            0.2637, 0.9530, 0.9928, 0.5478, 0.9917, 0.8166, 0.0703, 0.6142,\n",
       "            0.1398, 0.5660, 0.2493, 0.0348],\n",
       "           [0.6609, 0.5845, 0.8435, 0.6904, 0.5056, 0.2852, 0.6242, 0.6874,\n",
       "            0.9253, 0.3325, 0.0580, 0.4135, 0.5971, 0.4283, 0.8095, 0.1486,\n",
       "            0.3006, 0.3990, 0.9620, 0.4764, 0.6541, 0.5442, 0.7115, 0.6660,\n",
       "            0.5487, 0.9625, 0.9524, 0.7217]]]),\n",
       "  3))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MyDataset()\n",
    "dataset[0], dataset[1], dataset[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9a72e3e-3b8c-43a8-9061-acf99a0b987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\envs\\torch-book\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\envs\\torch-book\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0df2387e-f2d9-40be-838c-cf505fd5aca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 92 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "cat_directory = r'./data/dogs-vs-cats/Cat'\n",
    "dog_directory = r'./data/dogs-vs-cats/Dog'\n",
    "cat_images_filepaths = sorted([os.path.join(cat_directory, f) for f in\n",
    "                              os.listdir(cat_directory)])\n",
    "dog_images_filepaths = sorted([os.path.join(dog_directory, f) for f in\n",
    "                              os.listdir(dog_directory)])\n",
    "images_filepaths = [*cat_images_filepaths, *dog_images_filepaths]\n",
    "correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(correct_images_filepaths)\n",
    "train_images_filepaths = correct_images_filepaths[:400]\n",
    "val_images_filepaths = correct_images_filepaths[400:-10]\n",
    "test_images_filepaths = correct_images_filepaths[-10:]\n",
    "print(len(train_images_filepaths), len(val_images_filepaths), len(test_images_filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5906427e-5181-4708-a449-4d87655619e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogvsCatDataset(Dataset):\n",
    "    def __init__(self, file_list, transform = None, phase=\"train\"): # 전처리\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self): # 데이터셋의 전체 길이를 반환\n",
    "        return len(self.file_list)\n",
    "        self.data = list(range(100,200))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img, self.phase) # 이미지에 train 전처리 적용\n",
    "        label = img+path.split('/')[-1].split('.')[0]\n",
    "        if label == 'dog':\n",
    "            label = 1\n",
    "        elif label == 'cat':\n",
    "            label = 0\n",
    "        return img_transformed, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d59ce4f-bcaa-44ff-ae29-ef9e76c8c26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 126, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in data_loader:\n",
    "    optimizer.zero_grad() # 새로운 배치에 대한 기울기 계산 전에 이전값 초기화\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_label) # 예측값과 실제 레이블을 비교하여 손실을 계산\n",
    "    loss.backward() # 미분\n",
    "    optimizer.step() # 모델의 매개변수를 업데이트\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4c75a95-e043-489f-8e54-dba2ae2c7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "  # 생성자\n",
    "  def __init__(self):\n",
    "    super(LeNet5,self).__init__()\n",
    "    self.features = nn.Sequential(nn.Conv2d(1,6,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2),\n",
    "                                  nn.Conv2d(6,16,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2),\n",
    "                                  nn.Conv2d(16,126,kernel_size=5, padding='same'),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2))\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.classifier = nn.Sequential(nn.Linear(126*3*3, 128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(128, 64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(64, 2), # 2: 분류하고자 하는 가지수 \n",
    "                                    nn.Softmax(dim=1))\n",
    "  def forward(self,x):\n",
    "      x = self.features(x)\n",
    "      print(x.shape)\n",
    "      x = self.flatten(x)\n",
    "      x = self.classifier(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2e3eab4-011b-4a23-9df1-efb7fd0d7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "class MyDataset():\n",
    "    def __init__(self, root='./data/dogs-vs-cats'):\n",
    "        self.root = root\n",
    "        self.image_paths = []\n",
    "        self.__classes = {'Cat': 0, 'Dog': 1}\n",
    "        self.labels = []\n",
    "\n",
    "        for dname in os.listdir(self.root):\n",
    "            print(type(dname))\n",
    "            print(os.path.isdir(Path(root, dname)))\n",
    "            new_path = Path(root, dname)\n",
    "            if os.path.isdir(new_path):\n",
    "                for file in os.listdir(new_path):\n",
    "                    #print(file)\n",
    "                    self.image_paths.append(str(Path(new_path, file)))\n",
    "                    self.labels.append(self.__classes[dname])\n",
    "\n",
    "        self.transform = v2.Compose([ \n",
    "             v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "             v2.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        #print(path)\n",
    "        image = Image.open(path)\n",
    "        #print(self.transform(image).shape)\n",
    "        return self.transform(image) , self.labels[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d16d86d-48e2-4fae-b98e-416ad4f17979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "True\n",
      "<class 'str'>\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MyDataset('./data/dogs-vs-cats')\n",
    "data, label = dataset[0]\n",
    "data.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b5cff97-c759-4ba8-a036-7f2fa2125939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for X_train, y_label in data_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd657d99-4ddf-4f31-8ffb-10f769513026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91358061-fe63-42c3-bc67-2dc0d1e55f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, int)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_transform = v2.Compose([\n",
    "    v2.Resize(size=(224,224)),\n",
    "    v2.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ImageFolder('./data/dogs-vs-cats', transform=my_transform)\n",
    "image, label = dataset[0]\n",
    "type(image), type(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be43c9ba-d807-4d5e-b1ed-13ecd677196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size = 32)\n",
    "for X_train, y_label in data_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break\n",
    "\n",
    "# 3*224*224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8928348b-4324-4ca3-8a01-761dea501850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Old weights with accuracy 76.130%\n",
    "resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# New weights with accuracy 80.858%\n",
    "resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Best available weights (currently alias for IMAGENET1K_V2)\n",
    "# Note that these weights may change across versions\n",
    "resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Strings are also supported\n",
    "resnet50(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "# No weights - random initialization\n",
    "model = resnet50(weights=None)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0aed3abf-fc95-4069-b45a-ff5c3b45cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1000])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size = 32)\n",
    "for X_train, y_label in data_loader:\n",
    "    outputs = model(X_train) # ResNet50\n",
    "    print(outputs.shape)\n",
    "    break\n",
    "\n",
    "# 32*1000 -> Linear(-,2)로 바꿔줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63f00bff-7dd4-4e1e-a5a2-4760e7764159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. dataset (MNIST, My DataSet, ImageFolder(Cat, Dog 각각 데이터가 분류되어있어야 사용가능))\n",
    "# 2. DataLoader\n",
    "# 3. model (perceptron, ResNet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
