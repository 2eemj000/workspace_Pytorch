{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2efdd26b-235b-4ae1-87da-1ec944071a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. dataset (MNIST, My DataSet, ImageFolder(Cat, Dog 각각 데이터가 분류되어있어야 사용가능))\n",
    "# 2. DataLoader : 배치 단위로 데이터셋을 로드\n",
    "# 3. model (perceptron -> LeNet5 -> ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c56eb5d5-35fd-4a3d-8dc4-5ec62f230103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader \n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision.transforms.v2 as v2 # 데이터 전처리 변환(transform) 기능\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "# pip install torch-summary\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad25635-04a7-4312-9639-dff11c07b0f1",
   "metadata": {},
   "source": [
    "### LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a001946-8c3f-4565-a572-ebb2232577a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    # --- 이건 생성자\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.features = nn.Sequential(nn.Conv2d(1,6,kernel_size=5,padding=\"same\"), # 합성곱층 - 이미지 특징 추출(필터=커널 이용 이미지 스캔)\n",
    "                                      nn.ReLU(), # 활성화함수 - 비선형성으로 패턴 학습할 수 있도록\n",
    "                                      nn.MaxPool2d(2), # 풀링층 = 맵크기 줄임 - MaxPool은 그 구역에 가장 큰 값으로\n",
    "                                      nn.Conv2d(6,16,kernel_size=5,padding=\"same\"),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(2),\n",
    "                                      nn.Conv2d(16,126,kernel_size=5,padding=\"same\"),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(2))\n",
    "        \n",
    "        self.flatten = nn.Flatten() # 3차원을 1차원으로 바꿈\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(126*3*3,128), # 완전연결층 - 추출된 특징들을 조합하고 변환\n",
    "                                        nn.ReLU(), # 활성화함수\n",
    "                                        nn.Linear(128,64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64,10), # 10: 분류하고자 하는 가지수 \n",
    "                                        nn.Softmax(dim=1)) # 확률 분포로 변환\n",
    "        # 1134개->128개->64개->10개->확률 분포\n",
    "\n",
    "    # --- 이건 메서드인데, 입력 데이터가 모델을 통과하는 과정을 정의 (입력~출력)\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)      # 특징 추출 부분 (합성곱 + 풀링)\n",
    "        x = self.flatten(x)       # 3D -> 1D 변환\n",
    "        x = self.classifier(x)    # 분류 부분 (완전연결층)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e10a78-13c2-4313-8ef4-6c9123900edd",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c2f8b8-59a1-4cb3-a943-925cd435c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b528e4-030e-407e-acd7-1b024b9f0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.rand(64, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c25540e-2cec-4251-8772-a26f3e8b678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(\"data\", download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ca4170-41ad-43bc-97f4-e4093c2a8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca2b668-fba9-4bd7-a068-ab8c608525b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X_train, y_label in data_loader:\n",
    "  print(X_train.shape, y_label.shape)\n",
    "  break # 첫번째 배치의 (X_train.shape: 입력 데이터 배치의 형태, y_label.shape: 레이블 배치의 형태) 확인\n",
    "\n",
    "# torch.Size([32, 1, 28, 28]) : 배치크기는 32, 채널수는 1(흑백), 이미지크기는 28*28\n",
    "# torch.Size([32]) : 32개의 레이블 (32개 이미지 각각에 대한 정답을 나타내는 숫자들)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908895e-2a45-4b0b-9d08-8294845961cd",
   "metadata": {},
   "source": [
    "### Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99738d5d-22e8-451e-814e-cc96bcb4c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 1\n",
    "\n",
    "for _ in range(epochs):\n",
    "  for X_train, y_label in data_loader:\n",
    "    optimizer.zero_grad() # 새로운 배치에 대한 기울기 계산 전에 이전값 초기화\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_label) # 예측값과 실제 레이블을 비교하여 손실을 계산\n",
    "    loss.backward() # 미분\n",
    "    optimizer.step() # 모델의 매개변수를 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a99c21-6a24-4a1f-982d-b83e3793dbde",
   "metadata": {},
   "source": [
    "### MNIST, FashionMNIST, CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e9b0be-bf5b-4020-b21d-3e227fcd758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST('data', download=True, transform=v2.ToTensor())\n",
    "dataset = FashionMNIST('data', download=True, transform=v2.ToTensor())\n",
    "dataset = CIFAR10('data', download=True, transform=v2.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d865bcf0-1f59-4d0c-bc1d-08ba02e1bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20950fa7-4817-433b-b307-c924ed19721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5a120c-f6bc-4693-928b-89dbc6eb8e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "781.25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86b848-6caf-4ffe-a00b-5233b4ec42a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c31be13-bd8d-4c5c-a206-f9aa0b30400b",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f598167-f106-4f73-b312-87f3934b2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/vision/main/_modules/torchvision/models/alexnet.html#alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68774ee8-1897-46be-ba0a-6e9f08a248e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dad7cb67-25de-46e2-883c-ed91cebb7813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # (avgpool): AdaptiveAvgPool2d(output_size=(6, 6)) : 평균 풀링을 수행 -> 입력을 (6, 6) 크기로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c18a16e-c08c-4752-a293-836190efe4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (7): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier에서 out_features=1000 대신 분류하고자 하는 가지수(2)로 바꿔줘야하니까\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.Softmax() # 추가\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "035784ff-47fa-47f0-8431-b42eb4ae79a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          23,296\n",
      "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         307,392\n",
      "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         663,936\n",
      "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         884,992\n",
      "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         590,080\n",
      "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
      "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
      "├─Sequential: 1-3                        [-1, 2]                   --\n",
      "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
      "|    └─Linear: 2-15                      [-1, 512]                 4,719,104\n",
      "|    └─ReLU: 2-16                        [-1, 512]                 --\n",
      "|    └─Dropout: 2-17                     [-1, 512]                 --\n",
      "|    └─Linear: 2-18                      [-1, 64]                  32,832\n",
      "|    └─ReLU: 2-19                        [-1, 64]                  --\n",
      "|    └─Linear: 2-20                      [-1, 2]                   130\n",
      "|    └─Softmax: 2-21                     [-1, 2]                   --\n",
      "==========================================================================================\n",
      "Total params: 7,221,762\n",
      "Trainable params: 7,221,762\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 667.54\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.70\n",
      "Params size (MB): 27.55\n",
      "Estimated Total Size (MB): 31.83\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          23,296\n",
       "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         307,392\n",
       "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         663,936\n",
       "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
       "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         884,992\n",
       "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         590,080\n",
       "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
       "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
       "├─Sequential: 1-3                        [-1, 2]                   --\n",
       "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
       "|    └─Linear: 2-15                      [-1, 512]                 4,719,104\n",
       "|    └─ReLU: 2-16                        [-1, 512]                 --\n",
       "|    └─Dropout: 2-17                     [-1, 512]                 --\n",
       "|    └─Linear: 2-18                      [-1, 64]                  32,832\n",
       "|    └─ReLU: 2-19                        [-1, 64]                  --\n",
       "|    └─Linear: 2-20                      [-1, 2]                   130\n",
       "|    └─Softmax: 2-21                     [-1, 2]                   --\n",
       "==========================================================================================\n",
       "Total params: 7,221,762\n",
       "Trainable params: 7,221,762\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 667.54\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 3.70\n",
       "Params size (MB): 27.55\n",
       "Estimated Total Size (MB): 31.83\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "128c5a62-969d-400e-bba6-ca9169db4f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.rand(32,3,224,224)\n",
    "model(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e58affc3-1846-4143-ad9f-60a7b365f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([64, 3, 11, 11]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([64]) True\n",
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([192, 64, 5, 5]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([192]) True\n",
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([384, 192, 3, 3]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([384]) True\n",
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([256, 384, 3, 3]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([256]) True\n",
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([256]) True\n",
      "(None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([512, 9216]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "(None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([64, 512]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([64]) True\n",
      "(None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([2, 64]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([2]) True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.names, type(p), p.shape, p.requires_grad) # p.requires_grad를 true에서 false로 바꿔서 기록못하도록 바꿔줘야 미분가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e32f1c4-ecd0-4e0f-b1a8-ef33e5dab593",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0462c31-b3ee-44c6-b701-e3601ba11723",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    # print(p.names, type(p), p.shape, p.requires_grad)\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9daebac-5635-4a08-b200-b54e7a61acc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          (23,296)\n",
      "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         (307,392)\n",
      "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         (663,936)\n",
      "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         (884,992)\n",
      "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         (590,080)\n",
      "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
      "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
      "├─Sequential: 1-3                        [-1, 1000]                --\n",
      "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
      "|    └─Linear: 2-15                      [-1, 4096]                (37,752,832)\n",
      "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
      "|    └─Linear: 2-18                      [-1, 4096]                (16,781,312)\n",
      "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
      "|    └─Linear: 2-20                      [-1, 1000]                (4,097,000)\n",
      "==========================================================================================\n",
      "Total params: 61,100,840\n",
      "Trainable params: 0\n",
      "Non-trainable params: 61,100,840\n",
      "Total mult-adds (M): 775.28\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.77\n",
      "Params size (MB): 233.08\n",
      "Estimated Total Size (MB): 237.43\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 256, 6, 6]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 55, 55]          (23,296)\n",
       "|    └─ReLU: 2-2                         [-1, 64, 55, 55]          --\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 27, 27]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 192, 27, 27]         (307,392)\n",
       "|    └─ReLU: 2-5                         [-1, 192, 27, 27]         --\n",
       "|    └─MaxPool2d: 2-6                    [-1, 192, 13, 13]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 384, 13, 13]         (663,936)\n",
       "|    └─ReLU: 2-8                         [-1, 384, 13, 13]         --\n",
       "|    └─Conv2d: 2-9                       [-1, 256, 13, 13]         (884,992)\n",
       "|    └─ReLU: 2-10                        [-1, 256, 13, 13]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 13, 13]         (590,080)\n",
       "|    └─ReLU: 2-12                        [-1, 256, 13, 13]         --\n",
       "|    └─MaxPool2d: 2-13                   [-1, 256, 6, 6]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 256, 6, 6]           --\n",
       "├─Sequential: 1-3                        [-1, 1000]                --\n",
       "|    └─Dropout: 2-14                     [-1, 9216]                --\n",
       "|    └─Linear: 2-15                      [-1, 4096]                (37,752,832)\n",
       "|    └─ReLU: 2-16                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-17                     [-1, 4096]                --\n",
       "|    └─Linear: 2-18                      [-1, 4096]                (16,781,312)\n",
       "|    └─ReLU: 2-19                        [-1, 4096]                --\n",
       "|    └─Linear: 2-20                      [-1, 1000]                (4,097,000)\n",
       "==========================================================================================\n",
       "Total params: 61,100,840\n",
       "Trainable params: 0\n",
       "Non-trainable params: 61,100,840\n",
       "Total mult-adds (M): 775.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 3.77\n",
       "Params size (MB): 233.08\n",
       "Estimated Total Size (MB): 237.43\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6720c010-d1de-44a8-ae74-7485fd741c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (7): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.Softmax() # 추가\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f865696b-b94f-44ac-9e8e-81d0a8db7c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([64, 3, 11, 11]) False\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([64]) False\n",
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([192, 64, 5, 5]) False\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([192]) False\n",
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([384, 192, 3, 3]) False\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([384]) False\n",
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([256, 384, 3, 3]) False\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "(None, None, None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 3, 3]) False\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([256]) False\n",
      "(None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([512, 9216]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([512]) True\n",
      "(None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([64, 512]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([64]) True\n",
      "(None, None) <class 'torch.nn.parameter.Parameter'> torch.Size([2, 64]) True\n",
      "(None,) <class 'torch.nn.parameter.Parameter'> torch.Size([2]) True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.names, type(p), p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a893e8c1-abcb-4658-866e-7b5c4c699eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transform = v2.Compose([\n",
    "    v2.Resize((224,224)), # 이미지사이즈 맞춰주기\n",
    "    v2.ToTensor()\n",
    "])\n",
    "root = \"data/dogs-vs-cats\"\n",
    "dataset = ImageFolder(root, transform=my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "512573b8-a4fa-4b96-aebd-c0cb65eccd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for X_train, y_label in data_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c9c8512-55ad-4be3-b438-e03c3aadf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cf2a7cc-9bf8-40f7-a611-15099b1f0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자주 사용하니까 fit 메서드로 만들어둠\n",
    "def fit(model, data_loader, loss_fn, optimizer, epochs):\n",
    "    for i in range(epochs):\n",
    "        for X_train, y_label in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = loss_fn(outputs, y_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d635ef9-68e5-49d6-85bd-5c9ab0288f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit(model, data_loader, loss_fn, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e53e484a-8309-477d-904c-19eca37ad536",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_train, y_label in data_loader:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
