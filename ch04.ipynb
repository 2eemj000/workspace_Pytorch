{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92115981-ef38-4a48-a846-2675500e5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b3ef76-03ac-4032-98a4-29089cf15807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.tensor([[1,2],\n",
    "                    [3,4]])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c21e08-94e1-4b4a-8050-ea550eda16e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(temp.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e3f976-6fd0-4c0f-8f26-34c01cc51e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c417e1-1f81-4795-9615-535c66795652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eccb166c-1c84-4e58-afab-58fa0c2f8463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f7b4d9-ecc6-4052-8bbe-52d1d0f0f12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b7dc18-dd23-493b-ac6a-b1cce982afed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2edd0f-8b86-4065-bad6-9cbc13443216",
   "metadata": {},
   "outputs": [],
   "source": [
    "and_data = torch.tensor([ [0, 0],\n",
    "                          [0, 1],\n",
    "                          [1, 0],\n",
    "                          [1, 1]], dtype=torch.float32)\n",
    "and_labels = torch.tensor([ [1],\n",
    "                            [1],\n",
    "                            [1],\n",
    "                            [0]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96cdd17f-1a23-4ed4-86ef-16e2a567a09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.randn(3, 224, 224).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e442af-4310-4108-9307-d8a27d2b5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0000],\n",
       "        [0.2019],\n",
       "        [0.0620]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "l1 = nn.Linear(2, 1)\n",
    "x = l1(and_data)\n",
    "print(x.shape)\n",
    "torch.relu(x)\n",
    "\n",
    "act_fn = nn.ReLU()\n",
    "act_fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f14cf82d-e266-4460-9392-04f455e4b66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.5439, -0.1399]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3419], requires_grad=True),\n",
       " <bound method Module.parameters of Linear(in_features=2, out_features=1, bias=True)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weight, l1.bias, l1.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f8a295-5620-49af-bab0-e76d3d01741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #입력크기 2, 출력크기 1인 선형 레이어 정의함. \n",
    "        #self.fc2 = nn.Linear(2,1) 두번째 선형 레이어\n",
    "\n",
    "    def forward(self, x): #forward - 입력받아서 출력 변환과정을 정의함\n",
    "        x = self.fc1(x) #입력 x를 첫번째 선형레이어 fc1에 통과시킴. 선형변환 적용됨\n",
    "        x = self.sigmoid(x) #그 결과에 시그모이드 함수로 변환하여, 0과 1 사이로 이진 확률로 해석나옴\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2faf5ead-d6db-45cb-bcf8-5ba203603ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d893abb-f033-4e85-aa3c-dd78482271c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4655],\n",
       "        [0.3977],\n",
       "        [0.5618],\n",
       "        [0.4929]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(and_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27aa2969-5b4f-4432-8410-5c907006b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e1e7e8-179d-4a07-9f4f-097b585d1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63f69c0f-ac44-4527-957b-0408dbcf70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61091434-a028-45b0-ac23-e3d7611b3292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n",
      "loss tensor(-0., grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(and_data)\n",
    "    loss = loss_fn(outputs, and_labels)\n",
    "    print('loss', loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "# 가중치를 조금씩 조절하면서 for문 돌기\n",
    "# loss가 크게 줄지 않을 때까지 반복하도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7a1e4a6-2823-4573-b20e-1f7eacfffb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6001],\n",
       "        [0.5755],\n",
       "        [0.6106],\n",
       "        [0.5862]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(and_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9f3c910-d606-46d4-b7dc-6be3bba6fcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.2, 1.2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGiCAYAAADulWxzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlc0lEQVR4nO3db3CU1d3/8c8mIbtIzTqAhERCDFYlGKWSTCChmd5aiCCFYaYdwmATseCYVouQ1kpKK8I4k59tZdRiglrFYYo0twrWzqRIOrUQTRATkmlrdLSSmgC7pAmyCVhCSM7vAUNu12yAxFwbcvJ+zVwP9uy5dr97Jpz9cK4/6zLGGAEAAFgoYqgLAAAAcApBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYy9Ggs2/fPi1cuFDx8fFyuVx6/fXXL9h/586dmjt3rq6++mrFxMQoIyNDb775ppMlAgAAizkadE6dOqXp06dr8+bNl9R/3759mjt3rsrKylRTU6PbbrtNCxcuVG1trZNlAgAAS7nC9aOeLpdLu3bt0uLFi/u130033aScnBw98sgjzhQGAACsFTXUBVxId3e32tvbNXbs2D77dHR0qKOjI2if48ePa9y4cXK5XOEoEwAAfEXGGLW3tys+Pl4REYN3wOmyDjpPPPGETp06pSVLlvTZp6ioSBs2bAhjVQAAwClNTU2aNGnSoL3eZXvoaseOHVq5cqX++Mc/as6cOX32+/KKTiAQ0OTJk9XU1KSYmJivWjYAAAiDtrY2JSQk6MSJE/J6vYP2upflik5paalWrFihV1555YIhR5Lcbrfcbnev9piYGIIOAADDzGCfdnLZ3Udnx44dWr58uV5++WUtWLBgqMsBAADDmKMrOidPntS//vWvnscNDQ2qq6vT2LFjNXnyZBUWFurIkSPatm2bpHMhJy8vT0899ZRmzZolv98vSRo9evSgLmMBAICRwdEVnerqat1666269dZbJUkFBQW69dZbey4V9/l8amxs7On/7LPP6uzZs7r//vsVFxfXsz344INOlgkAACwVtpORw6WtrU1er1eBQIBzdAAAGCac+v6+7M7RAQAAGCwEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1ooa6AIRHV7fRgYbjam4/rQlXepSeNFaREa6hLgsARpbuLunTSunkMelrsVJiphQROdRVWY2gMwLs/qdPG/5UL1/gdE9bnNej9QunaV5K3BBWBgAjSP0b0u6Hpbaj/9cWEy/Ne1yatmjo6rKco4eu9u3bp4ULFyo+Pl4ul0uvv/76RffZu3evUlNT5fF4NGXKFG3ZssXJEq23+58+/fD3B4NCjiT5A6f1w98f1O5/+oaoMgAYQerfkP43LzjkSFKb71x7/RtDU9cI4GjQOXXqlKZPn67NmzdfUv+GhgbdeeedysrKUm1trX7+859r1apVeu2115ws01pd3UYb/lQvE+K5820b/lSvru5QPQAAg6K769xKzoVm491rz/XDoHP00NX8+fM1f/78S+6/ZcsWTZ48WU8++aQkKTk5WdXV1frNb36j7373uyH36ejoUEdHR8/jtra2r1SzTQ40HO+1kvNFRpIvcFoHGo4r47px4SsMAEaSTyt7r+QEMVLbkXP9krLCVtZIcVlddVVVVaXs7OygtjvuuEPV1dXq7OwMuU9RUZG8Xm/PlpCQEI5Sh4Xm9r5DzkD6AQAG4OSxwe2Hfrmsgo7f71dsbGxQW2xsrM6ePauWlpaQ+xQWFioQCPRsTU1N4Sh1WJhwpWdQ+wEABuBrsRfv059+6JfL7qorlyv4kmdjTMj289xut9xut+N1DUfpSWMV5/XIHzgd8siwS9JE77lLzQEADknMPHd1VZtPoc/TcZ17PjEz3JWNCJfVis7EiRPl9/uD2pqbmxUVFaVx4ziHpL8iI1xav3CapHOh5ovOP16/cBr30wEAJ0VEnruEXFKfs/G8/8f9dBxyWQWdjIwMlZeXB7Xt2bNHaWlpGjVq1BBVNbzNS4lTyfdnaKI3+PDURK9HJd+fwX10ACAcpi2SlmyTYr4058bEn2vnPjqOcfTQ1cmTJ/Wvf/2r53FDQ4Pq6uo0duxYTZ48WYWFhTpy5Ii2bdsmScrPz9fmzZtVUFCge++9V1VVVXrhhRe0Y8cOJ8u03ryUOM2dNpE7IwPAUJq2SJq6gDsjh5mjQae6ulq33XZbz+OCggJJ0t13362XXnpJPp9PjY2NPc8nJSWprKxMa9as0TPPPKP4+Hg9/fTTfV5ajksXGeHiEnIAGGoRkVxCHmYuc/5sX0u0tbXJ6/UqEAgoJiZmqMsBAACXwKnv78vqHB0AAIDBRNABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1gpL0CkuLlZSUpI8Ho9SU1NVUVFxwf7bt2/X9OnTdcUVVyguLk733HOPWltbw1EqAACwiONBp7S0VKtXr9a6detUW1urrKwszZ8/X42NjSH7v/3228rLy9OKFSv0/vvv65VXXtF7772nlStXOl0qAACwjONBZ9OmTVqxYoVWrlyp5ORkPfnkk0pISFBJSUnI/vv379e1116rVatWKSkpSd/85jd13333qbq6OmT/jo4OtbW1BW0AAACSw0HnzJkzqqmpUXZ2dlB7dna2KisrQ+6TmZmpw4cPq6ysTMYYHTt2TK+++qoWLFgQsn9RUZG8Xm/PlpCQMOifAwAADE+OBp2WlhZ1dXUpNjY2qD02NlZ+vz/kPpmZmdq+fbtycnIUHR2tiRMn6qqrrtJvf/vbkP0LCwsVCAR6tqampkH/HAAAYHgKy8nILpcr6LExplfbefX19Vq1apUeeeQR1dTUaPfu3WpoaFB+fn7I/m63WzExMUEbAACAJEU5+eLjx49XZGRkr9Wb5ubmXqs85xUVFWn27Nl66KGHJEm33HKLxowZo6ysLD322GOKi4tzsmQAAGARR1d0oqOjlZqaqvLy8qD28vJyZWZmhtzn888/V0REcFmRkZGSzq0EAQAAXCrHD10VFBTod7/7nV588UV98MEHWrNmjRobG3sORRUWFiovL6+n/8KFC7Vz506VlJTo0KFDeuedd7Rq1Sqlp6crPj7e6XIBAIBFHD10JUk5OTlqbW3Vxo0b5fP5lJKSorKyMiUmJkqSfD5f0D11li9frvb2dm3evFk/+clPdNVVV+n222/X448/7nSpAADAMi5j2fGgtrY2eb1eBQIBTkwGAGCYcOr7m9+6AgAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYKS9ApLi5WUlKSPB6PUlNTVVFRccH+HR0dWrdunRITE+V2u3XdddfpxRdfDEepAADAIlFOv0FpaalWr16t4uJizZ49W88++6zmz5+v+vp6TZ48OeQ+S5Ys0bFjx/TCCy/o61//upqbm3X27FmnSwUAAJZxGWOMk28wc+ZMzZgxQyUlJT1tycnJWrx4sYqKinr13717t5YuXapDhw5p7Nix/X6/trY2eb1eBQIBxcTEfKXaAQBAeDj1/e3ooaszZ86opqZG2dnZQe3Z2dmqrKwMuc8bb7yhtLQ0/epXv9I111yjG264QT/96U/13//+N2T/jo4OtbW1BW0AAACSw4euWlpa1NXVpdjY2KD22NhY+f3+kPscOnRIb7/9tjwej3bt2qWWlhb96Ec/0vHjx0Oep1NUVKQNGzY4Uj8AABjewnIyssvlCnpsjOnVdl53d7dcLpe2b9+u9PR03Xnnndq0aZNeeumlkKs6hYWFCgQCPVtTU5MjnwEAAAw/jq7ojB8/XpGRkb1Wb5qbm3ut8pwXFxena665Rl6vt6ctOTlZxhgdPnxY119/fVB/t9stt9s9+MUDAIBhz9EVnejoaKWmpqq8vDyovby8XJmZmSH3mT17to4ePaqTJ0/2tH300UeKiIjQpEmTnCwXAABYxvFDVwUFBfrd736nF198UR988IHWrFmjxsZG5efnSzp36CkvL6+n/7JlyzRu3Djdc889qq+v1759+/TQQw/pBz/4gUaPHu10uQAAwCKO30cnJydHra2t2rhxo3w+n1JSUlRWVqbExERJks/nU2NjY0//r33tayovL9ePf/xjpaWlady4cVqyZIkee+wxp0sFAACWcfw+OuHGfXQAABh+huV9dAAAAIYSQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYKyxBp7i4WElJSfJ4PEpNTVVFRcUl7ffOO+8oKipK3/jGN5wtEAAAWMnxoFNaWqrVq1dr3bp1qq2tVVZWlubPn6/GxsYL7hcIBJSXl6dvf/vbTpcIAAAs5TLGGCffYObMmZoxY4ZKSkp62pKTk7V48WIVFRX1ud/SpUt1/fXXKzIyUq+//rrq6uou6f3a2trk9XoVCAQUExPzVcsHAABh4NT3t6MrOmfOnFFNTY2ys7OD2rOzs1VZWdnnflu3btUnn3yi9evXX/Q9Ojo61NbWFrQBAABIDgedlpYWdXV1KTY2Nqg9NjZWfr8/5D4ff/yx1q5dq+3btysqKuqi71FUVCSv19uzJSQkDErtAABg+AvLycgulyvosTGmV5skdXV1admyZdqwYYNuuOGGS3rtwsJCBQKBnq2pqWlQagYAAMPfxZdMvoLx48crMjKy1+pNc3Nzr1UeSWpvb1d1dbVqa2v1wAMPSJK6u7tljFFUVJT27Nmj22+/PWgft9stt9vt3IcAAADDlqMrOtHR0UpNTVV5eXlQe3l5uTIzM3v1j4mJ0T/+8Q/V1dX1bPn5+brxxhtVV1enmTNnOlkuAACwjKMrOpJUUFCg3NxcpaWlKSMjQ88995waGxuVn58v6dyhpyNHjmjbtm2KiIhQSkpK0P4TJkyQx+Pp1Q4AAHAxjgednJwctba2auPGjfL5fEpJSVFZWZkSExMlST6f76L31AEAABgIx++jE27cRwcAgOFnWN5HBwAAYCgRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1whJ0iouLlZSUJI/Ho9TUVFVUVPTZd+fOnZo7d66uvvpqxcTEKCMjQ2+++WY4ygQAAJZxPOiUlpZq9erVWrdunWpra5WVlaX58+ersbExZP99+/Zp7ty5KisrU01NjW677TYtXLhQtbW1TpcKAAAs4zLGGCffYObMmZoxY4ZKSkp62pKTk7V48WIVFRVd0mvcdNNNysnJ0SOPPHLRvm1tbfJ6vQoEAoqJiRlw3QAAIHyc+v52dEXnzJkzqqmpUXZ2dlB7dna2KisrL+k1uru71d7errFjx4Z8vqOjQ21tbUEbAACA5HDQaWlpUVdXl2JjY4PaY2Nj5ff7L+k1nnjiCZ06dUpLliwJ+XxRUZG8Xm/PlpCQ8JXrBgAAdgjLycgulyvosTGmV1soO3bs0KOPPqrS0lJNmDAhZJ/CwkIFAoGerampaVBqBgAAw1+Uky8+fvx4RUZG9lq9aW5u7rXK82WlpaVasWKFXnnlFc2ZM6fPfm63W263e1DqBQAAdnF0RSc6OlqpqakqLy8Pai8vL1dmZmaf++3YsUPLly/Xyy+/rAULFjhZIgAAsJijKzqSVFBQoNzcXKWlpSkjI0PPPfecGhsblZ+fL+ncoacjR45o27Ztks6FnLy8PD311FOaNWtWz2rQ6NGj5fV6nS4XAABYxPGgk5OTo9bWVm3cuFE+n08pKSkqKytTYmKiJMnn8wXdU+fZZ5/V2bNndf/99+v+++/vab/77rv10ksvOV0uAACwiOP30Qk37qMDAMDwMyzvowMAADCUCDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAa0UNdQEIj65uowMNx9XcfloTrvQoPWmsIiNcQ10WAIwozMXhR9AZAXb/06cNf6qXL3C6py3O69H6hdM0LyVuCCsDgJGDuXhohOXQVXFxsZKSkuTxeJSamqqKiooL9t+7d69SU1Pl8Xg0ZcoUbdmyJRxlWmn3P3364e8PBv3DkiR/4LR++PuD2v1P3xBVBgAjB3Px0HE86JSWlmr16tVat26damtrlZWVpfnz56uxsTFk/4aGBt15553KyspSbW2tfv7zn2vVqlV67bXXnC7VOl3dRhv+VC8T4rnzbRv+VK+u7lA9AACDgbl4aDkedDZt2qQVK1Zo5cqVSk5O1pNPPqmEhASVlJSE7L9lyxZNnjxZTz75pJKTk7Vy5Ur94Ac/0G9+85uQ/Ts6OtTW1ha04ZwDDcd7/e/hi4wkX+C0DjQcD19RADDCMBcPLUeDzpkzZ1RTU6Ps7Oyg9uzsbFVWVobcp6qqqlf/O+64Q9XV1ers7OzVv6ioSF6vt2dLSEgYvA8wzDW39/0PayD9AAD9x1w8tBwNOi0tLerq6lJsbGxQe2xsrPx+f8h9/H5/yP5nz55VS0tLr/6FhYUKBAI9W1NT0+B9gGFuwpWeQe0HAOg/5uKhFZarrlyu4EvnjDG92i7WP1S7JLndbrnd7kGo0j7pSWMV5/XIHzgd8tiwS9JE77nLGwEAzmAuHlqOruiMHz9ekZGRvVZvmpube63anDdx4sSQ/aOiojRu3DjHarVRZIRL6xdOk3TuH9IXnX+8fuE07uEAAA5iLh5ajgad6Ohopaamqry8PKi9vLxcmZmZIffJyMjo1X/Pnj1KS0vTqFGjHKvVVvNS4lTy/Rma6A1eEp3o9ajk+zO4dwMAhAFz8dBxmfPHhRxSWlqq3NxcbdmyRRkZGXruuef0/PPP6/3331diYqIKCwt15MgRbdu2TdK5y8tTUlJ033336d5771VVVZXy8/O1Y8cOffe7373o+7W1tcnr9SoQCCgmJsbJjzascDdOABh6zMV9c+r72/FzdHJyctTa2qqNGzfK5/MpJSVFZWVlSkxMlCT5fL6ge+okJSWprKxMa9as0TPPPKP4+Hg9/fTTlxRy0LfICJcyruPQHwAMJebi8HN8RSfcWNEBAGD4cer7m18vBwAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGsRdAAAgLUIOgAAwFoEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACwFkEHAABYi6ADAACsRdABAADWIugAAABrEXQAAIC1CDoAAMBaBB0AAGAtgg4AALAWQQcAAFiLoAMAAKxF0AEAANYi6AAAAGs5GnQ+++wz5ebmyuv1yuv1Kjc3VydOnOizf2dnpx5++GHdfPPNGjNmjOLj45WXl6ejR486WSYAALCUo0Fn2bJlqqur0+7du7V7927V1dUpNze3z/6ff/65Dh48qF/+8pc6ePCgdu7cqY8++kiLFi1yskwAAGAplzHGOPHCH3zwgaZNm6b9+/dr5syZkqT9+/crIyNDH374oW688cZLep333ntP6enp+vTTTzV58uRez3d0dKijo6PncSAQ0OTJk9XU1KSYmJjB+TAAAMBRbW1tSkhI0IkTJ+T1egftdaMG7ZW+pKqqSl6vtyfkSNKsWbPk9XpVWVl5yUEnEAjI5XLpqquuCvl8UVGRNmzY0Ks9ISFhQHUDAICh09raOjyCjt/v14QJE3q1T5gwQX6//5Je4/Tp01q7dq2WLVvW5+pMYWGhCgoKeh6fOHFCiYmJamxsHNSBssH5tMxqV2+MTd8Ym74xNn1jbPrG2IR2/ojM2LFjB/V1+x10Hn300ZArKF/03nvvSZJcLlev54wxIdu/rLOzU0uXLlV3d7eKi4v77Od2u+V2u3u1e71e/oD6EBMTw9j0gbHpG2PTN8amb4xN3xib0CIiBvf04X4HnQceeEBLly69YJ9rr71Wf//733Xs2LFez/3nP/9RbGzsBffv7OzUkiVL1NDQoL/+9a/8IQAAgAHpd9AZP368xo8ff9F+GRkZCgQCOnDggNLT0yVJ7777rgKBgDIzM/vc73zI+fjjj/XWW29p3Lhx/S0RAABAkoOXlycnJ2vevHm69957tX//fu3fv1/33nuvvvOd7wSdiDx16lTt2rVLknT27Fl973vfU3V1tbZv366uri75/X75/X6dOXPmkt7X7XZr/fr1IQ9njXSMTd8Ym74xNn1jbPrG2PSNsQnNqXFx7PJySTp+/LhWrVqlN954Q5K0aNEibd68OegKKpfLpa1bt2r58uX697//raSkpJCv9dZbb+l//ud/nCoVAABYyNGgAwAAMJT4rSsAAGAtgg4AALAWQQcAAFiLoAMAAKxlRdD57LPPlJubK6/XK6/Xq9zcXJ04caLP/p2dnXr44Yd18803a8yYMYqPj1deXp6OHj0avqIdUlxcrKSkJHk8HqWmpqqiouKC/ffu3avU1FR5PB5NmTJFW7ZsCVOl4defsdm5c6fmzp2rq6++WjExMcrIyNCbb74ZxmrDq79/N+e98847ioqK0je+8Q1nCxxC/R2bjo4OrVu3TomJiXK73bruuuv04osvhqna8Orv2Gzfvl3Tp0/XFVdcobi4ON1zzz1qbW0NU7XhsW/fPi1cuFDx8fFyuVx6/fXXL7rPSJmH+zs2gzYPGwvMmzfPpKSkmMrKSlNZWWlSUlLMd77znT77nzhxwsyZM8eUlpaaDz/80FRVVZmZM2ea1NTUMFY9+P7whz+YUaNGmeeff97U19ebBx980IwZM8Z8+umnIfsfOnTIXHHFFebBBx809fX15vnnnzejRo0yr776apgrd15/x+bBBx80jz/+uDlw4ID56KOPTGFhoRk1apQ5ePBgmCt3Xn/H5rwTJ06YKVOmmOzsbDN9+vTwFBtmAxmbRYsWmZkzZ5ry8nLT0NBg3n33XfPOO++Eserw6O/YVFRUmIiICPPUU0+ZQ4cOmYqKCnPTTTeZxYsXh7lyZ5WVlZl169aZ1157zUgyu3btumD/kTQP93dsBmseHvZBp76+3kgy+/fv72mrqqoyksyHH354ya9z4MABI+mik/vlLD093eTn5we1TZ061axduzZk/5/97Gdm6tSpQW333XefmTVrlmM1DpX+jk0o06ZNMxs2bBjs0obcQMcmJyfH/OIXvzDr16+3Nuj0d2z+/Oc/G6/Xa1pbW8NR3pDq79j8+te/NlOmTAlqe/rpp82kSZMcq3GoXcqX+Uiah7/oUsYmlIHMw8P+0FVVVZW8Xq9mzpzZ0zZr1ix5vV5VVlZe8usEAgG5XK6gmxkOJ2fOnFFNTY2ys7OD2rOzs/sch6qqql7977jjDlVXV6uzs9OxWsNtIGPzZd3d3Wpvbx/0X9UdagMdm61bt+qTTz7R+vXrnS5xyAxkbN544w2lpaXpV7/6la655hrdcMMN+ulPf6r//ve/4Sg5bAYyNpmZmTp8+LDKyspkjNGxY8f06quvasGCBeEo+bI1UubhwTDQebjfv3V1ufH7/ZowYUKv9gkTJsjv91/Sa5w+fVpr167VsmXLhu0PiLa0tKirq6vXD6bGxsb2OQ5+vz9k/7Nnz6qlpUVxcXGO1RtOAxmbL3viiSd06tQpLVmyxIkSh8xAxubjjz/W2rVrVVFRoaioYT+F9GkgY3Po0CG9/fbb8ng82rVrl1paWvSjH/1Ix48ft+o8nYGMTWZmprZv366cnBydPn1aZ8+e1aJFi/Tb3/42HCVftkbKPDwYBjoPX7YrOo8++qhcLtcFt+rqaknnfkbiy4wxIdu/rLOzU0uXLlV3d7eKi4sH/XOE25c/88XGIVT/UO026O/YnLdjxw49+uijKi0tDRmqbXCpY9PV1aVly5Zpw4YNuuGGG8JV3pDqz99Nd3e3XC6Xtm/frvT0dN15553atGmTXnrpJetWdaT+jU19fb1WrVqlRx55RDU1Ndq9e7caGhqUn58fjlIvayNpHh6orzIPX7b/HXvggQe0dOnSC/a59tpr9fe//13Hjh3r9dx//vOfXin5y87/UnpDQ4P++te/DtvVHOncr8pHRkb2+t9Uc3Nzn+MwceLEkP2joqKs+tX4gYzNeaWlpVqxYoVeeeUVzZkzx8kyh0R/x6a9vV3V1dWqra3VAw88IOncl7sxRlFRUdqzZ49uv/32sNTutIH83cTFxemaa66R1+vtaUtOTpYxRocPH9b111/vaM3hMpCxKSoq0uzZs/XQQw9Jkm655RaNGTNGWVlZeuyxx0bsysVImYe/iq86D1+2Kzrjx4/X1KlTL7h5PB5lZGQoEAjowIEDPfu+++67CgQCyszM7PP1z4ecjz/+WH/5y1+G/R9UdHS0UlNTVV5eHtReXl7e5zhkZGT06r9nzx6lpaVp1KhRjtUabgMZG+nc/yCWL1+ul19+2drzCPo7NjExMfrHP/6hurq6ni0/P1833nij6urqgs6VG+4G8ncze/ZsHT16VCdPnuxp++ijjxQREaFJkyY5Wm84DWRsPv/8c0VEBH/lREZGSvq/FYyRaKTMwwM1KPNwv095vgzNmzfP3HLLLaaqqspUVVWZm2++udfl5TfeeKPZuXOnMcaYzs5Os2jRIjNp0iRTV1dnfD5fz9bR0TEUH2FQnL/c84UXXjD19fVm9erVZsyYMebf//63McaYtWvXmtzc3J7+5y9rXLNmjamvrzcvvPCCtZc19ndsXn75ZRMVFWWeeeaZoL+PEydODNVHcEx/x+bLbL7qqr9j097ebiZNmmS+973vmffff9/s3bvXXH/99WblypVD9REc09+x2bp1q4mKijLFxcXmk08+MW+//bZJS0sz6enpQ/URHNHe3m5qa2tNbW2tkWQ2bdpkamtre67oHcnzcH/HZrDmYSuCTmtrq7nrrrvMlVdeaa688kpz1113mc8++yyojySzdetWY4wxDQ0NRlLI7a233gp7/YPpmWeeMYmJiSY6OtrMmDHD7N27t+e5u+++23zrW98K6v+3v/3N3HrrrSY6Otpce+21pqSkJMwVh09/xuZb3/pWyL+Pu+++O/yFh0F//26+yOagY0z/x+aDDz4wc+bMMaNHjzaTJk0yBQUF5vPPPw9z1eHR37F5+umnzbRp08zo0aNNXFycueuuu8zhw4fDXLWz3nrrrQvOHSN5Hu7v2AzWPOwyZgSvGQIAAKtdtufoAAAAfFUEHQAAYC2CDgAAsBZBBwAAWIugAwAArEXQAQAA1iLoAAAAaxF0AACAtQg6AADAWgQdAABgLYIOAACw1v8Hob+CTxjzPCMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = [0, 0, 1]\n",
    "y1 = [0, 1, 0]\n",
    "x2 = [1]\n",
    "y2 = [1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x1, y1)\n",
    "ax.scatter(x2, y2)\n",
    "# ax.plot(x3, y3)\n",
    "ax.set_xlim(-0.2, 1.2)\n",
    "ax.set_ylim(-0.2, 1.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
